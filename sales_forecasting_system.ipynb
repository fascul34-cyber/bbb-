{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–¥–∞–∂ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≥—Ä—É–∑–æ–∫\n",
        "## Wildberries & Ozon\n",
        "\n",
        "**–¶–µ–ª—å:** –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–∏—Å—Ç–µ–º—É rolling-–ø—Ä–æ–≥–Ω–æ–∑–∞ –ø—Ä–æ–¥–∞–∂ –Ω–∞ 18 –º–µ—Å—è—Ü–µ–≤ —Å –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—Ç–≥—Ä—É–∑–æ–∫\n",
        "\n",
        "**–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö:** 26.03.2024 ‚Äì 20.12.2025 (–¥–Ω–µ–≤–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞)\n",
        "\n",
        "**–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä:** solo-code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from prophet import Prophet\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É CSV –∏ Excel —Ñ–∞–π–ª–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "    \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (CSV –∏–ª–∏ Excel)\"\"\"\n",
        "    if file_path.endswith('.csv'):\n",
        "        return pd.read_csv(file_path, encoding='utf-8')\n",
        "    elif file_path.endswith(('.xlsx', '.xls')):\n",
        "        return pd.read_excel(file_path)\n",
        "    else:\n",
        "        raise ValueError(f\"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_path}\")\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂\n",
        "try:\n",
        "    wb_sales = load_data('wb_sales.csv')\n",
        "    print(f\"‚úÖ WB –ø—Ä–æ–¥–∞–∂–∏: {wb_sales.shape}\")\n",
        "except:\n",
        "    try:\n",
        "        wb_sales = load_data('wb_sales.xlsx')\n",
        "        print(f\"‚úÖ WB –ø—Ä–æ–¥–∞–∂–∏: {wb_sales.shape}\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è –§–∞–π–ª wb_sales –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö\")\n",
        "        dates = pd.date_range('2024-03-26', '2025-12-20', freq='D')\n",
        "        wb_sales = pd.DataFrame({\n",
        "            '–î–∞—Ç–∞': dates,\n",
        "            'solo-code': 'SKU001',\n",
        "            'SKU': 'SKU001',\n",
        "            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.': np.random.poisson(10, len(dates))\n",
        "        })\n",
        "\n",
        "try:\n",
        "    ozon_sales = load_data('ozon_sales.csv')\n",
        "    print(f\"‚úÖ Ozon –ø—Ä–æ–¥–∞–∂–∏: {ozon_sales.shape}\")\n",
        "except:\n",
        "    try:\n",
        "        ozon_sales = load_data('ozon_sales.xlsx')\n",
        "        print(f\"‚úÖ Ozon –ø—Ä–æ–¥–∞–∂–∏: {ozon_sales.shape}\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è –§–∞–π–ª ozon_sales –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö\")\n",
        "        dates = pd.date_range('2024-03-26', '2025-12-20', freq='D')\n",
        "        ozon_sales = pd.DataFrame({\n",
        "            '–î–∞—Ç–∞': dates,\n",
        "            'solo-code': 'SKU001',\n",
        "            'SKU': 'SKU001',\n",
        "            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.': np.random.poisson(8, len(dates))\n",
        "        })\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤\n",
        "try:\n",
        "    wb_stocks = load_data('wb_stocks.csv')\n",
        "    print(f\"‚úÖ WB –æ—Å—Ç–∞—Ç–∫–∏: {wb_stocks.shape}\")\n",
        "except:\n",
        "    try:\n",
        "        wb_stocks = load_data('wb_stocks.xlsx')\n",
        "        print(f\"‚úÖ WB –æ—Å—Ç–∞—Ç–∫–∏: {wb_stocks.shape}\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è –§–∞–π–ª wb_stocks –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö\")\n",
        "        dates = pd.date_range('2024-03-26', '2025-12-20', freq='D')\n",
        "        wb_stocks = pd.DataFrame({\n",
        "            '–î–∞—Ç–∞': dates,\n",
        "            '–°–∫–ª–∞–¥': 'WB',\n",
        "            'solo-code': 'SKU001',\n",
        "            'SKU': 'SKU001',\n",
        "            '–û—Å—Ç–∞—Ç–æ–∫': np.random.randint(50, 200, len(dates))\n",
        "        })\n",
        "\n",
        "try:\n",
        "    ozon_stocks = load_data('ozon_stocks.csv')\n",
        "    print(f\"‚úÖ Ozon –æ—Å—Ç–∞—Ç–∫–∏: {ozon_stocks.shape}\")\n",
        "except:\n",
        "    try:\n",
        "        ozon_stocks = load_data('ozon_stocks.xlsx')\n",
        "        print(f\"‚úÖ Ozon –æ—Å—Ç–∞—Ç–∫–∏: {ozon_stocks.shape}\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è –§–∞–π–ª ozon_stocks –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö\")\n",
        "        dates = pd.date_range('2024-03-26', '2025-12-20', freq='D')\n",
        "        ozon_stocks = pd.DataFrame({\n",
        "            '–î–∞—Ç–∞': dates,\n",
        "            '–°–∫–ª–∞–¥': 'Ozon',\n",
        "            'solo-code': 'SKU001',\n",
        "            'SKU': 'SKU001',\n",
        "            '–û—Å—Ç–∞—Ç–æ–∫': np.random.randint(40, 150, len(dates))\n",
        "        })\n",
        "\n",
        "try:\n",
        "    our_stocks = load_data('our_stocks.csv')\n",
        "    print(f\"‚úÖ –ù–∞—à–∏ –æ—Å—Ç–∞—Ç–∫–∏: {our_stocks.shape}\")\n",
        "except:\n",
        "    try:\n",
        "        our_stocks = load_data('our_stocks.xlsx')\n",
        "        print(f\"‚úÖ –ù–∞—à–∏ –æ—Å—Ç–∞—Ç–∫–∏: {our_stocks.shape}\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è –§–∞–π–ª our_stocks –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö\")\n",
        "        dates = pd.date_range('2024-03-26', '2025-12-20', freq='D')\n",
        "        our_stocks = pd.DataFrame({\n",
        "            '–î–∞—Ç–∞': dates,\n",
        "            'solo-code': 'SKU001',\n",
        "            'SKU': 'SKU001',\n",
        "            '–û—Å—Ç–∞—Ç–æ–∫': np.random.randint(100, 300, len(dates))\n",
        "        })\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤\n",
        "try:\n",
        "    withdraw = load_data('withdraw.csv')\n",
        "    print(f\"‚úÖ –¢–æ–≤–∞—Ä—ã –Ω–∞ –≤—ã–≤–æ–¥: {withdraw.shape}\")\n",
        "except:\n",
        "    try:\n",
        "        withdraw = load_data('withdraw.xlsx')\n",
        "        print(f\"‚úÖ –¢–æ–≤–∞—Ä—ã –Ω–∞ –≤—ã–≤–æ–¥: {withdraw.shape}\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è –§–∞–π–ª withdraw –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π\")\n",
        "        withdraw = pd.DataFrame(columns=['solo-code', 'SKU'])\n",
        "\n",
        "try:\n",
        "    defecture = load_data('defecture.csv')\n",
        "    print(f\"‚úÖ –î–µ—Ñ–µ–∫—Ç—É—Ä–∞: {defecture.shape}\")\n",
        "except:\n",
        "    try:\n",
        "        defecture = load_data('defecture.xlsx')\n",
        "        print(f\"‚úÖ –î–µ—Ñ–µ–∫—Ç—É—Ä–∞: {defecture.shape}\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è –§–∞–π–ª defecture –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π\")\n",
        "        defecture = pd.DataFrame(columns=['solo-code', 'SKU', '–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç—É—Ä—ã'])\n",
        "\n",
        "try:\n",
        "    count_box = load_data('count_box.csv')\n",
        "    print(f\"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –∫–æ—Ä–æ–±–µ: {count_box.shape}\")\n",
        "except:\n",
        "    try:\n",
        "        count_box = load_data('count_box.xlsx')\n",
        "        print(f\"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –∫–æ—Ä–æ–±–µ: {count_box.shape}\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è –§–∞–π–ª count_box –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä\")\n",
        "        count_box = pd.DataFrame({\n",
        "            'solo-code': ['SKU001'],\n",
        "            '–ö–æ–ª-–≤–æ': [12]\n",
        "        })\n",
        "\n",
        "print(\"\\nüìä –û–±–∑–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
        "print(f\"WB –ø—Ä–æ–¥–∞–∂–∏: {wb_sales.shape}\")\n",
        "print(f\"Ozon –ø—Ä–æ–¥–∞–∂–∏: {ozon_sales.shape}\")\n",
        "print(f\"WB –æ—Å—Ç–∞—Ç–∫–∏: {wb_stocks.shape}\")\n",
        "print(f\"Ozon –æ—Å—Ç–∞—Ç–∫–∏: {ozon_stocks.shape}\")\n",
        "print(f\"–ù–∞—à–∏ –æ—Å—Ç–∞—Ç–∫–∏: {our_stocks.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### 2.1. –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –¥–∞—Ç –∫ datetime –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä—è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_dates(df, date_col='–î–∞—Ç–∞'):\n",
        "    \"\"\"–ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –¥–∞—Ç –∫ datetime\"\"\"\n",
        "    df = df.copy()\n",
        "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
        "    return df\n",
        "\n",
        "# –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –¥–∞—Ç\n",
        "wb_sales = prepare_dates(wb_sales)\n",
        "ozon_sales = prepare_dates(ozon_sales)\n",
        "wb_stocks = prepare_dates(wb_stocks)\n",
        "ozon_stocks = prepare_dates(ozon_stocks)\n",
        "our_stocks = prepare_dates(our_stocks)\n",
        "\n",
        "if '–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç—É—Ä—ã' in defecture.columns:\n",
        "    defecture['–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç—É—Ä—ã'] = pd.to_datetime(defecture['–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç—É—Ä—ã'], errors='coerce')\n",
        "\n",
        "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞\n",
        "all_dates = []\n",
        "for df in [wb_sales, ozon_sales, wb_stocks, ozon_stocks, our_stocks]:\n",
        "    if '–î–∞—Ç–∞' in df.columns:\n",
        "        all_dates.extend(df['–î–∞—Ç–∞'].dropna().tolist())\n",
        "\n",
        "min_date = min(all_dates) if all_dates else pd.Timestamp('2024-03-26')\n",
        "max_date = max(all_dates) if all_dates else pd.Timestamp('2025-12-20')\n",
        "\n",
        "print(f\"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {min_date.date()} - {max_date.date()}\")\n",
        "print(f\"üìÖ –í—Å–µ–≥–æ –¥–Ω–µ–π: {(max_date - min_date).days + 1}\")\n",
        "\n",
        "# –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö solo-code\n",
        "all_solo_codes = set()\n",
        "for df in [wb_sales, ozon_sales, wb_stocks, ozon_stocks, our_stocks]:\n",
        "    if 'solo-code' in df.columns:\n",
        "        all_solo_codes.update(df['solo-code'].dropna().unique())\n",
        "\n",
        "all_solo_codes = sorted(list(all_solo_codes))\n",
        "print(f\"üì¶ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö solo-code: {len(all_solo_codes)}\")\n",
        "print(f\"üì¶ –ü—Ä–∏–º–µ—Ä—ã: {all_solo_codes[:5]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_full_calendar(min_date, max_date, solo_codes):\n",
        "    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä—è –¥–ª—è –≤—Å–µ—Ö solo-code\"\"\"\n",
        "    dates = pd.date_range(min_date, max_date, freq='D')\n",
        "    calendar = []\n",
        "    for solo_code in solo_codes:\n",
        "        for date in dates:\n",
        "            calendar.append({'–î–∞—Ç–∞': date, 'solo-code': solo_code})\n",
        "    return pd.DataFrame(calendar)\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä—è\n",
        "full_calendar = create_full_calendar(min_date, max_date, all_solo_codes)\n",
        "print(f\"üìÖ –ü–æ–ª–Ω—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä—å: {full_calendar.shape}\")\n",
        "print(f\"üìÖ –ü—Ä–∏–º–µ—Ä –∫–∞–ª–µ–Ω–¥–∞—Ä—è:\")\n",
        "print(full_calendar.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–¥–∞–∂: –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –Ω—É–ª—è–º–∏\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_sales(df, calendar, channel_name):\n",
        "    \"\"\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–¥–∞–∂ —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø—É—Å–∫–æ–≤\"\"\"\n",
        "    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –¥–∞—Ç–µ –∏ solo-code\n",
        "    sales_agg = df.groupby(['–î–∞—Ç–∞', 'solo-code'])['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'].sum().reset_index()\n",
        "    \n",
        "    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∫–∞–ª–µ–Ω–¥–∞—Ä–µ–º\n",
        "    sales_full = calendar.merge(sales_agg, on=['–î–∞—Ç–∞', 'solo-code'], how='left')\n",
        "    sales_full['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'] = sales_full['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'].fillna(0)\n",
        "    sales_full['–ö–∞–Ω–∞–ª'] = channel_name\n",
        "    \n",
        "    return sales_full\n",
        "\n",
        "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–¥–∞–∂\n",
        "wb_sales_processed = process_sales(wb_sales, full_calendar, 'WB')\n",
        "ozon_sales_processed = process_sales(ozon_sales, full_calendar, 'Ozon')\n",
        "\n",
        "# –°—É–º–º–∞—Ä–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏\n",
        "total_sales = wb_sales_processed.merge(\n",
        "    ozon_sales_processed[['–î–∞—Ç–∞', 'solo-code', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.']],\n",
        "    on=['–î–∞—Ç–∞', 'solo-code'],\n",
        "    how='left',\n",
        "    suffixes=('_wb', '_ozon')\n",
        ")\n",
        "total_sales['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'] = (\n",
        "    total_sales['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫._wb'].fillna(0) + \n",
        "    total_sales['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫._ozon'].fillna(0)\n",
        ")\n",
        "total_sales = total_sales[['–î–∞—Ç–∞', 'solo-code', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.']].copy()\n",
        "total_sales['–ö–∞–Ω–∞–ª'] = 'Total'\n",
        "\n",
        "print(\"‚úÖ –ü—Ä–æ–¥–∞–∂–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã\")\n",
        "print(f\"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º:\")\n",
        "print(f\"WB - –ø—Ä–æ–ø—É—Å–∫–æ–≤: {(wb_sales_processed['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'] == 0).sum() / len(wb_sales_processed) * 100:.1f}%\")\n",
        "print(f\"Ozon - –ø—Ä–æ–ø—É—Å–∫–æ–≤: {(ozon_sales_processed['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'] == 0).sum() / len(ozon_sales_processed) * 100:.1f}%\")\n",
        "print(f\"\\nüìä –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö WB:\")\n",
        "print(wb_sales_processed.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤: forward/backward fill\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_stocks(df, calendar, stock_name):\n",
        "    \"\"\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤ —Å forward/backward fill\"\"\"\n",
        "    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –¥–∞—Ç–µ –∏ solo-code (–µ—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–∫–ª–∞–¥–æ–≤ - —Å—É–º–º–∏—Ä—É–µ–º)\n",
        "    if '–°–∫–ª–∞–¥' in df.columns:\n",
        "        stocks_agg = df.groupby(['–î–∞—Ç–∞', 'solo-code'])['–û—Å—Ç–∞—Ç–æ–∫'].sum().reset_index()\n",
        "    else:\n",
        "        stocks_agg = df.groupby(['–î–∞—Ç–∞', 'solo-code'])['–û—Å—Ç–∞—Ç–æ–∫'].sum().reset_index()\n",
        "    \n",
        "    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∫–∞–ª–µ–Ω–¥–∞—Ä–µ–º\n",
        "    stocks_full = calendar.merge(stocks_agg, on=['–î–∞—Ç–∞', 'solo-code'], how='left')\n",
        "    \n",
        "    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ solo-code –∏ –¥–∞—Ç–µ\n",
        "    stocks_full = stocks_full.sort_values(['solo-code', '–î–∞—Ç–∞'])\n",
        "    \n",
        "    # Forward fill, –∑–∞—Ç–µ–º backward fill –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä—è–¥–∞\n",
        "    stocks_full['–û—Å—Ç–∞—Ç–æ–∫'] = stocks_full.groupby('solo-code')['–û—Å—Ç–∞—Ç–æ–∫'].fillna(method='ffill')\n",
        "    stocks_full['–û—Å—Ç–∞—Ç–æ–∫'] = stocks_full.groupby('solo-code')['–û—Å—Ç–∞—Ç–æ–∫'].fillna(method='bfill')\n",
        "    stocks_full['–û—Å—Ç–∞—Ç–æ–∫'] = stocks_full['–û—Å—Ç–∞—Ç–æ–∫'].fillna(0)\n",
        "    \n",
        "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
        "    stocks_full['–û—Å—Ç–∞—Ç–æ–∫'] = stocks_full['–û—Å—Ç–∞—Ç–æ–∫'].clip(lower=0)\n",
        "    \n",
        "    stocks_full['–¢–∏–ø_–æ—Å—Ç–∞—Ç–∫–∞'] = stock_name\n",
        "    \n",
        "    return stocks_full\n",
        "\n",
        "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤\n",
        "wb_stocks_processed = process_stocks(wb_stocks, full_calendar, 'WB')\n",
        "ozon_stocks_processed = process_stocks(ozon_stocks, full_calendar, 'Ozon')\n",
        "our_stocks_processed = process_stocks(our_stocks, full_calendar, 'Our')\n",
        "\n",
        "print(\"‚úÖ –û—Å—Ç–∞—Ç–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã\")\n",
        "print(f\"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ—Å—Ç–∞—Ç–∫–∞–º:\")\n",
        "print(f\"WB –æ—Å—Ç–∞—Ç–∫–∏ - —Å—Ä–µ–¥–Ω–µ–µ: {wb_stocks_processed['–û—Å—Ç–∞—Ç–æ–∫'].mean():.1f}\")\n",
        "print(f\"Ozon –æ—Å—Ç–∞—Ç–∫–∏ - —Å—Ä–µ–¥–Ω–µ–µ: {ozon_stocks_processed['–û—Å—Ç–∞—Ç–æ–∫'].mean():.1f}\")\n",
        "print(f\"–ù–∞—à–∏ –æ—Å—Ç–∞—Ç–∫–∏ - —Å—Ä–µ–¥–Ω–µ–µ: {our_stocks_processed['–û—Å—Ç–∞—Ç–æ–∫'].mean():.1f}\")\n",
        "print(f\"\\nüìä –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –æ—Å—Ç–∞—Ç–∫–æ–≤:\")\n",
        "print(wb_stocks_processed.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4. –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"üìä –°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –î–ê–ù–ù–´–ú\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nüì¶ –ü—Ä–æ–¥–∞–∂–∏:\")\n",
        "print(f\"  - WB: {len(wb_sales_processed)} –∑–∞–ø–∏—Å–µ–π, {wb_sales_processed['solo-code'].nunique()} —Ç–æ–≤–∞—Ä–æ–≤\")\n",
        "print(f\"  - Ozon: {len(ozon_sales_processed)} –∑–∞–ø–∏—Å–µ–π, {ozon_sales_processed['solo-code'].nunique()} —Ç–æ–≤–∞—Ä–æ–≤\")\n",
        "print(f\"  - Total: {len(total_sales)} –∑–∞–ø–∏—Å–µ–π, {total_sales['solo-code'].nunique()} —Ç–æ–≤–∞—Ä–æ–≤\")\n",
        "\n",
        "print(f\"\\nüè¨ –û—Å—Ç–∞—Ç–∫–∏:\")\n",
        "print(f\"  - WB: {len(wb_stocks_processed)} –∑–∞–ø–∏—Å–µ–π\")\n",
        "print(f\"  - Ozon: {len(ozon_stocks_processed)} –∑–∞–ø–∏—Å–µ–π\")\n",
        "print(f\"  - –ù–∞—à–∏: {len(our_stocks_processed)} –∑–∞–ø–∏—Å–µ–π\")\n",
        "\n",
        "print(f\"\\nüìà –ü—Ä–æ–ø—É—Å–∫–∏ –≤ –ø—Ä–æ–¥–∞–∂–∞—Ö (–Ω—É–ª–µ–≤—ã–µ –¥–Ω–∏):\")\n",
        "for solo_code in all_solo_codes[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5\n",
        "    wb_data = wb_sales_processed[wb_sales_processed['solo-code'] == solo_code]\n",
        "    ozon_data = ozon_sales_processed[ozon_sales_processed['solo-code'] == solo_code]\n",
        "    total_data = total_sales[total_sales['solo-code'] == solo_code]\n",
        "    \n",
        "    wb_zeros = (wb_data['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'] == 0).sum() / len(wb_data) * 100\n",
        "    ozon_zeros = (ozon_data['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'] == 0).sum() / len(ozon_data) * 100\n",
        "    total_zeros = (total_data['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'] == 0).sum() / len(total_data) * 100\n",
        "    \n",
        "    print(f\"  {solo_code}: WB={wb_zeros:.1f}%, Ozon={ozon_zeros:.1f}%, Total={total_zeros:.1f}%\")\n",
        "\n",
        "print(\"\\n‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. EDA –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–ø—Ä–æ—Å–∞\n",
        "\n",
        "–î–ª—è –∫–∞–∂–¥–æ–≥–æ solo-code –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º:\n",
        "- –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–¥–∞–∂\n",
        "- –î–æ–ª—è –Ω—É–ª–µ–≤—ã—Ö –¥–Ω–µ–π\n",
        "- –°—Ä–µ–¥–Ω–∏–π —Å–ø—Ä–æ—Å\n",
        "- –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏ (CV)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_demand_metrics(sales_data, solo_code):\n",
        "    \"\"\"–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Å–ø—Ä–æ—Å–∞ –¥–ª—è —Ç–æ–≤–∞—Ä–∞\"\"\"\n",
        "    data = sales_data[sales_data['solo-code'] == solo_code].copy()\n",
        "    data = data.sort_values('–î–∞—Ç–∞')\n",
        "    \n",
        "    demand = data['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'].values\n",
        "    \n",
        "    metrics = {\n",
        "        'solo-code': solo_code,\n",
        "        'mean_demand': np.mean(demand),\n",
        "        'std_demand': np.std(demand),\n",
        "        'cv': np.std(demand) / (np.mean(demand) + 1e-6),  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏\n",
        "        'zero_ratio': (demand == 0).sum() / len(demand),\n",
        "        'total_demand': np.sum(demand),\n",
        "        'max_demand': np.max(demand),\n",
        "        'min_demand': np.min(demand)\n",
        "    }\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "# –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤\n",
        "demand_metrics = []\n",
        "for solo_code in all_solo_codes:\n",
        "    metrics = calculate_demand_metrics(total_sales, solo_code)\n",
        "    demand_metrics.append(metrics)\n",
        "\n",
        "demand_df = pd.DataFrame(demand_metrics)\n",
        "\n",
        "print(\"üìä –ú–µ—Ç—Ä–∏–∫–∏ —Å–ø—Ä–æ—Å–∞ –ø–æ —Ç–æ–≤–∞—Ä–∞–º:\")\n",
        "print(demand_df.head(10))\n",
        "print(f\"\\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
        "print(demand_df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_demand(zero_ratio, cv):\n",
        "    \"\"\"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ —Å–ø—Ä–æ—Å–∞\"\"\"\n",
        "    if zero_ratio > 0.5:\n",
        "        return 'intermittent'  # –ü—Ä–µ—Ä—ã–≤–∏—Å—Ç—ã–π —Å–ø—Ä–æ—Å (>50% –Ω—É–ª–µ–π)\n",
        "    elif cv > 1.0:\n",
        "        return 'seasonal'  # –°–µ–∑–æ–Ω–Ω—ã–π/–Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–π (–≤—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å)\n",
        "    else:\n",
        "        return 'stable'  # –°—Ç–∞–±–∏–ª—å–Ω—ã–π —Å–ø—Ä–æ—Å\n",
        "\n",
        "# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
        "demand_df['demand_type'] = demand_df.apply(\n",
        "    lambda x: classify_demand(x['zero_ratio'], x['cv']), \n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"üìä –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–ø—Ä–æ—Å–∞:\")\n",
        "print(demand_df['demand_type'].value_counts())\n",
        "print(f\"\\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º:\")\n",
        "print(demand_df.groupby('demand_type').agg({\n",
        "    'mean_demand': 'mean',\n",
        "    'cv': 'mean',\n",
        "    'zero_ratio': 'mean'\n",
        "}).round(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ —Ç–æ–≤–∞—Ä–∞\n",
        "example_solo_code = all_solo_codes[0]\n",
        "example_data = total_sales[total_sales['solo-code'] == example_solo_code].sort_values('–î–∞—Ç–∞')\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–¥–∞–∂\n",
        "axes[0].plot(example_data['–î–∞—Ç–∞'], example_data['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'], linewidth=1.5)\n",
        "axes[0].set_title(f'–ü—Ä–æ–¥–∞–∂–∏ –ø–æ –¥–Ω—è–º: {example_solo_code}', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('–î–∞—Ç–∞')\n",
        "axes[0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫–æ–≤–æ–∫')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø—Ä–æ—Å–∞\n",
        "axes[1].hist(example_data['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'], bins=30, edgecolor='black', alpha=0.7)\n",
        "axes[1].set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø—Ä–æ—Å–∞: {example_solo_code}', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫–æ–≤–æ–∫')\n",
        "axes[1].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞\n",
        "example_metrics = demand_df[demand_df['solo-code'] == example_solo_code].iloc[0]\n",
        "print(f\"\\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è {example_solo_code}:\")\n",
        "print(f\"  –¢–∏–ø —Å–ø—Ä–æ—Å–∞: {example_metrics['demand_type']}\")\n",
        "print(f\"  –°—Ä–µ–¥–Ω–∏–π —Å–ø—Ä–æ—Å: {example_metrics['mean_demand']:.2f}\")\n",
        "print(f\"  CV: {example_metrics['cv']:.2f}\")\n",
        "print(f\"  –î–æ–ª—è –Ω—É–ª–µ–π: {example_metrics['zero_ratio']:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "–°–æ–∑–¥–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö:\n",
        "- –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏, –º–µ—Å—è—Ü, –∫–≤–∞—Ä—Ç–∞–ª –∏ —Ç.–¥.)\n",
        "- –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (sin/cos)\n",
        "- –ü—Ä–∞–∑–¥–Ω–∏–∫–∏ –†–§ —Å –æ–∫–Ω–∞–º–∏ –≤–ª–∏—è–Ω–∏—è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_calendar_features(df):\n",
        "    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "    df['day_of_week'] = df['–î–∞—Ç–∞'].dt.dayofweek  # 0=–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫, 6=–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ\n",
        "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
        "    df['week_of_year'] = df['–î–∞—Ç–∞'].dt.isocalendar().week\n",
        "    df['month'] = df['–î–∞—Ç–∞'].dt.month\n",
        "    df['quarter'] = df['–î–∞—Ç–∞'].dt.quarter\n",
        "    df['year'] = df['–î–∞—Ç–∞'].dt.year\n",
        "    df['day_of_month'] = df['–î–∞—Ç–∞'].dt.day\n",
        "    df['day_of_year'] = df['–î–∞—Ç–∞'].dt.dayofyear\n",
        "    \n",
        "    # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–µ—Å—è—Ü–∞ (12 –º–µ—Å—è—Ü–µ–≤)\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    \n",
        "    # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –Ω–µ–¥–µ–ª–∏ (52 –Ω–µ–¥–µ–ª–∏)\n",
        "    df['week_sin'] = np.sin(2 * np.pi * df['week_of_year'] / 52)\n",
        "    df['week_cos'] = np.cos(2 * np.pi * df['week_of_year'] / 52)\n",
        "    \n",
        "    # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –¥–Ω—è –Ω–µ–¥–µ–ª–∏ (7 –¥–Ω–µ–π)\n",
        "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
        "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# –ü—Ä–∏–º–µ–Ω—è–µ–º –∫ –ø—Ä–æ–¥–∞–∂–∞–º\n",
        "total_sales = create_calendar_features(total_sales)\n",
        "wb_sales_processed = create_calendar_features(wb_sales_processed)\n",
        "ozon_sales_processed = create_calendar_features(ozon_sales_processed)\n",
        "\n",
        "print(\"‚úÖ –ë–∞–∑–æ–≤—ã–µ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–∑–¥–∞–Ω—ã\")\n",
        "print(f\"\\nüìä –ü—Ä–∏–º–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\")\n",
        "print(total_sales[['–î–∞—Ç–∞', 'day_of_week', 'is_weekend', 'month', 'quarter', \n",
        "                   'month_sin', 'month_cos']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_holiday_features(df):\n",
        "    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ –†–§ —Å –æ–∫–Ω–∞–º–∏ –≤–ª–∏—è–Ω–∏—è\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # –ù–æ–≤—ã–π –≥–æ–¥: 15.12 - 10.01\n",
        "    df['is_new_year_period'] = 0\n",
        "    df.loc[\n",
        "        ((df['–î–∞—Ç–∞'].dt.month == 12) & (df['–î–∞—Ç–∞'].dt.day >= 15)) |\n",
        "        ((df['–î–∞—Ç–∞'].dt.month == 1) & (df['–î–∞—Ç–∞'].dt.day <= 10)),\n",
        "        'is_new_year_period'\n",
        "    ] = 1\n",
        "    \n",
        "    # 14 —Ñ–µ–≤—Ä–∞–ª—è: ¬±7 –¥–Ω–µ–π\n",
        "    df['is_feb_14_window'] = 0\n",
        "    for year in df['–î–∞—Ç–∞'].dt.year.unique():\n",
        "        feb_14 = pd.Timestamp(f'{year}-02-14')\n",
        "        mask = (df['–î–∞—Ç–∞'] >= feb_14 - timedelta(days=7)) & (df['–î–∞—Ç–∞'] <= feb_14 + timedelta(days=7))\n",
        "        df.loc[mask, 'is_feb_14_window'] = 1\n",
        "    \n",
        "    # 23 —Ñ–µ–≤—Ä–∞–ª—è: ¬±7 –¥–Ω–µ–π\n",
        "    df['is_feb_23_window'] = 0\n",
        "    for year in df['–î–∞—Ç–∞'].dt.year.unique():\n",
        "        feb_23 = pd.Timestamp(f'{year}-02-23')\n",
        "        mask = (df['–î–∞—Ç–∞'] >= feb_23 - timedelta(days=7)) & (df['–î–∞—Ç–∞'] <= feb_23 + timedelta(days=7))\n",
        "        df.loc[mask, 'is_feb_23_window'] = 1\n",
        "    \n",
        "    # 8 –º–∞—Ä—Ç–∞: ¬±7 –¥–Ω–µ–π\n",
        "    df['is_mar_8_window'] = 0\n",
        "    for year in df['–î–∞—Ç–∞'].dt.year.unique():\n",
        "        mar_8 = pd.Timestamp(f'{year}-03-08')\n",
        "        mask = (df['–î–∞—Ç–∞'] >= mar_8 - timedelta(days=7)) & (df['–î–∞—Ç–∞'] <= mar_8 + timedelta(days=7))\n",
        "        df.loc[mask, 'is_mar_8_window'] = 1\n",
        "    \n",
        "    # 1 —Å–µ–Ω—Ç—è–±—Ä—è: ¬±7 –¥–Ω–µ–π\n",
        "    df['is_sep_1_window'] = 0\n",
        "    for year in df['–î–∞—Ç–∞'].dt.year.unique():\n",
        "        sep_1 = pd.Timestamp(f'{year}-09-01')\n",
        "        mask = (df['–î–∞—Ç–∞'] >= sep_1 - timedelta(days=7)) & (df['–î–∞—Ç–∞'] <= sep_1 + timedelta(days=7))\n",
        "        df.loc[mask, 'is_sep_1_window'] = 1\n",
        "    \n",
        "    # –ß–µ—Ä–Ω–∞—è –ø—è—Ç–Ω–∏—Ü–∞: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –Ω–µ–¥–µ–ª–∏ –Ω–æ—è–±—Ä—è\n",
        "    df['is_black_friday_period'] = 0\n",
        "    df.loc[\n",
        "        (df['–î–∞—Ç–∞'].dt.month == 11) & (df['–î–∞—Ç–∞'].dt.day >= 15),\n",
        "        'is_black_friday_period'\n",
        "    ] = 1\n",
        "    \n",
        "    return df\n",
        "\n",
        "# –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "total_sales = create_holiday_features(total_sales)\n",
        "wb_sales_processed = create_holiday_features(wb_sales_processed)\n",
        "ozon_sales_processed = create_holiday_features(ozon_sales_processed)\n",
        "\n",
        "print(\"‚úÖ –ü—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–∑–¥–∞–Ω—ã\")\n",
        "print(f\"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∞–∑–¥–Ω–∏–∫–∞–º:\")\n",
        "holiday_cols = ['is_new_year_period', 'is_feb_14_window', 'is_feb_23_window', \n",
        "                'is_mar_8_window', 'is_sep_1_window', 'is_black_friday_period']\n",
        "print(total_sales[holiday_cols].sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏\n",
        "holiday_corr = []\n",
        "for solo_code in all_solo_codes[:10]:  # –ü–µ—Ä–≤—ã–µ 10 —Ç–æ–≤–∞—Ä–æ–≤\n",
        "    data = total_sales[total_sales['solo-code'] == solo_code]\n",
        "    for holiday in holiday_cols:\n",
        "        if data[holiday].sum() > 0:  # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –¥–Ω–∏\n",
        "            corr = data['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'].corr(data[holiday])\n",
        "            holiday_corr.append({\n",
        "                'solo-code': solo_code,\n",
        "                'holiday': holiday,\n",
        "                'correlation': corr\n",
        "            })\n",
        "\n",
        "if holiday_corr:\n",
        "    holiday_corr_df = pd.DataFrame(holiday_corr)\n",
        "    print(\"\\nüìä –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏ (–ø—Ä–∏–º–µ—Ä—ã):\")\n",
        "    print(holiday_corr_df.groupby('holiday')['correlation'].mean().sort_values(ascending=False))\n",
        "\n",
        "# –ü—Ä–∏–º–µ—Ä –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "print(\"\\nüìä –ü—Ä–∏–º–µ—Ä –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\")\n",
        "example_calendar = total_sales[\n",
        "    ['–î–∞—Ç–∞', 'day_of_week', 'is_weekend', 'month', 'is_new_year_period', \n",
        "     'is_feb_14_window', 'is_mar_8_window', 'is_black_friday_period']\n",
        "].head(20)\n",
        "print(example_calendar)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∏–∑–Ω–µ—Å-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π\n",
        "\n",
        "### 5.1. –¢–æ–≤–∞—Ä—ã –Ω–∞ –≤—ã–≤–æ–¥ (withdraw)\n",
        "### 5.2. –î–µ—Ñ–µ–∫—Ç—É—Ä–∞ (defecture)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_withdraw_constraint(sales_df, stocks_wb, stocks_ozon, stocks_our, withdraw_df):\n",
        "    \"\"\"–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ –≤—ã–≤–æ–¥\"\"\"\n",
        "    if len(withdraw_df) == 0:\n",
        "        return sales_df.copy(), stocks_wb.copy(), stocks_ozon.copy(), stocks_our.copy()\n",
        "    \n",
        "    withdraw_codes = set(withdraw_df['solo-code'].unique())\n",
        "    \n",
        "    sales_df = sales_df.copy()\n",
        "    stocks_wb = stocks_wb.copy()\n",
        "    stocks_ozon = stocks_ozon.copy()\n",
        "    stocks_our = stocks_our.copy()\n",
        "    \n",
        "    # –î–ª—è —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ –≤—ã–≤–æ–¥: –ø—Ä–æ–¥–∞–∂–∏ = 0, –æ—Å—Ç–∞—Ç–∫–∏ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è\n",
        "    for solo_code in withdraw_codes:\n",
        "        # –ü—Ä–æ–¥–∞–∂–∏ = 0\n",
        "        sales_df.loc[sales_df['solo-code'] == solo_code, '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'] = 0\n",
        "        \n",
        "        # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤ –¥–æ –Ω—É–ª—è\n",
        "        for stocks_df in [stocks_wb, stocks_ozon, stocks_our]:\n",
        "            mask = stocks_df['solo-code'] == solo_code\n",
        "            if mask.sum() > 0:\n",
        "                total_stock = stocks_df.loc[mask, '–û—Å—Ç–∞—Ç–æ–∫'].iloc[-1]  # –ü–æ—Å–ª–µ–¥–Ω–∏–π –æ—Å—Ç–∞—Ç–æ–∫\n",
        "                days_left = len(stocks_df.loc[mask])\n",
        "                if days_left > 0:\n",
        "                    daily_decrease = total_stock / days_left\n",
        "                    stocks_df.loc[mask, '–û—Å—Ç–∞—Ç–æ–∫'] = np.maximum(\n",
        "                        0, \n",
        "                        total_stock - np.arange(days_left) * daily_decrease\n",
        "                    )\n",
        "    \n",
        "    return sales_df, stocks_wb, stocks_ozon, stocks_our\n",
        "\n",
        "# –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –≤—ã–≤–æ–¥\n",
        "total_sales, wb_stocks_processed, ozon_stocks_processed, our_stocks_processed = apply_withdraw_constraint(\n",
        "    total_sales, wb_stocks_processed, ozon_stocks_processed, our_stocks_processed, withdraw\n",
        ")\n",
        "\n",
        "print(\"‚úÖ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –≤—ã–≤–æ–¥ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã\")\n",
        "if len(withdraw) > 0:\n",
        "    print(f\"üì¶ –¢–æ–≤–∞—Ä–æ–≤ –Ω–∞ –≤—ã–≤–æ–¥: {len(withdraw)}\")\n",
        "    print(f\"üì¶ –ö–æ–¥—ã: {withdraw['solo-code'].unique()[:5]}\")\n",
        "else:\n",
        "    print(\"üì¶ –¢–æ–≤–∞—Ä–æ–≤ –Ω–∞ –≤—ã–≤–æ–¥ –Ω–µ—Ç\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_defecture_constraint(sales_df, defecture_df):\n",
        "    \"\"\"–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –¥–µ—Ñ–µ–∫—Ç—É—Ä—ã\"\"\"\n",
        "    if len(defecture_df) == 0:\n",
        "        return sales_df.copy()\n",
        "    \n",
        "    sales_df = sales_df.copy()\n",
        "    \n",
        "    for idx, row in defecture_df.iterrows():\n",
        "        solo_code = row['solo-code']\n",
        "        end_date = row['–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç—É—Ä—ã']\n",
        "        \n",
        "        if pd.isna(end_date):\n",
        "            continue\n",
        "        \n",
        "        # –í –ø–µ—Ä–∏–æ–¥ –¥–æ –æ–∫–æ–Ω—á–∞–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç—É—Ä—ã: –ø—Ä–æ–¥–∞–∂–∏ = 0\n",
        "        mask = (sales_df['solo-code'] == solo_code) & (sales_df['–î–∞—Ç–∞'] <= end_date)\n",
        "        sales_df.loc[mask, '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'] = 0\n",
        "    \n",
        "    return sales_df\n",
        "\n",
        "# –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç—É—Ä—ã\n",
        "total_sales = apply_defecture_constraint(total_sales, defecture)\n",
        "\n",
        "print(\"‚úÖ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç—É—Ä—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã\")\n",
        "if len(defecture) > 0:\n",
        "    print(f\"‚ö†Ô∏è –¢–æ–≤–∞—Ä–æ–≤ –≤ –¥–µ—Ñ–µ–∫—Ç—É—Ä–µ: {len(defecture)}\")\n",
        "    print(f\"‚ö†Ô∏è –ü—Ä–∏–º–µ—Ä—ã:\")\n",
        "    print(defecture.head())\n",
        "else:\n",
        "    print(\"‚úÖ –î–µ—Ñ–µ–∫—Ç—É—Ä—ã –Ω–µ—Ç\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. –ú–æ–¥–µ–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "\n",
        "–†–µ–∞–ª–∏–∑—É–µ–º –Ω–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ solo-code:\n",
        "- Baseline (Naive, Moving Average, Seasonal Naive)\n",
        "- –î–ª—è intermittent demand (Croston, SBA, TSB)\n",
        "- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ (Linear Regression, ARIMA, SARIMA, SARIMAX, Prophet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline –º–æ–¥–µ–ª–∏\n",
        "\n",
        "def naive_forecast(data, horizon):\n",
        "    \"\"\"Naive: –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\"\"\"\n",
        "    last_value = data.iloc[-1]\n",
        "    return [last_value] * horizon\n",
        "\n",
        "def moving_average_forecast(data, window=7, horizon=30):\n",
        "    \"\"\"Moving Average\"\"\"\n",
        "    ma_value = data[-window:].mean()\n",
        "    return [ma_value] * horizon\n",
        "\n",
        "def seasonal_naive_forecast(data, season_length=7, horizon=30):\n",
        "    \"\"\"Seasonal Naive: –∑–Ω–∞—á–µ–Ω–∏–µ —Å –ø—Ä–æ—à–ª–æ–≥–æ —Å–µ–∑–æ–Ω–∞\"\"\"\n",
        "    if len(data) < season_length:\n",
        "        return [data.mean()] * horizon\n",
        "    seasonal_values = data[-season_length:].values\n",
        "    forecast = []\n",
        "    for i in range(horizon):\n",
        "        forecast.append(seasonal_values[i % season_length])\n",
        "    return forecast\n",
        "\n",
        "print(\"‚úÖ Baseline –º–æ–¥–µ–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ú–æ–¥–µ–ª–∏ –¥–ª—è intermittent demand\n",
        "\n",
        "def croston_forecast(data, alpha=0.1, horizon=30):\n",
        "    \"\"\"Croston's method –¥–ª—è –ø—Ä–µ—Ä—ã–≤–∏—Å—Ç–æ–≥–æ —Å–ø—Ä–æ—Å–∞\"\"\"\n",
        "    if len(data) < 2:\n",
        "        return [data.mean()] * horizon\n",
        "    \n",
        "    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –Ω–µ–Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã\n",
        "    non_zero = data[data > 0]\n",
        "    if len(non_zero) < 2:\n",
        "        return [non_zero.mean() if len(non_zero) > 0 else 0] * horizon\n",
        "    \n",
        "    # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∑–∞–∫–∞–∑–∞\n",
        "    sizes = non_zero.values\n",
        "    avg_size = sizes[0]\n",
        "    for size in sizes[1:]:\n",
        "        avg_size = alpha * size + (1 - alpha) * avg_size\n",
        "    \n",
        "    # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞\n",
        "    intervals = []\n",
        "    last_idx = 0\n",
        "    for i in range(1, len(data)):\n",
        "        if data.iloc[i] > 0:\n",
        "            intervals.append(i - last_idx)\n",
        "            last_idx = i\n",
        "    \n",
        "    if len(intervals) < 2:\n",
        "        avg_interval = len(data) / max(len(non_zero), 1)\n",
        "    else:\n",
        "        avg_interval = intervals[0]\n",
        "        for interval in intervals[1:]:\n",
        "            avg_interval = alpha * interval + (1 - alpha) * avg_interval\n",
        "    \n",
        "    # –ü—Ä–æ–≥–Ω–æ–∑ = —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä / —Å—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª\n",
        "    forecast_demand = avg_size / max(avg_interval, 1)\n",
        "    \n",
        "    return [forecast_demand] * horizon\n",
        "\n",
        "def sba_forecast(data, alpha=0.1, horizon=30):\n",
        "    \"\"\"Syntetos-Boylan Approximation\"\"\"\n",
        "    croston_fc = croston_forecast(data, alpha, horizon)\n",
        "    # SBA = Croston * (1 - alpha/2)\n",
        "    return [x * (1 - alpha / 2) for x in croston_fc]\n",
        "\n",
        "def tsb_forecast(data, alpha=0.1, beta=0.1, horizon=30):\n",
        "    \"\"\"Teunter-Syntetos-Babai method\"\"\"\n",
        "    if len(data) < 2:\n",
        "        return [data.mean()] * horizon\n",
        "    \n",
        "    non_zero = data[data > 0]\n",
        "    if len(non_zero) < 2:\n",
        "        return [non_zero.mean() if len(non_zero) > 0 else 0] * horizon\n",
        "    \n",
        "    # –†–∞–∑–º–µ—Ä –∑–∞–∫–∞–∑–∞\n",
        "    sizes = non_zero.values\n",
        "    avg_size = sizes[0]\n",
        "    for size in sizes[1:]:\n",
        "        avg_size = alpha * size + (1 - alpha) * avg_size\n",
        "    \n",
        "    # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–µ–Ω—É–ª–µ–≤–æ–≥–æ —Å–ø—Ä–æ—Å–∞\n",
        "    prob = (data > 0).sum() / len(data)\n",
        "    last_prob = prob\n",
        "    for i in range(1, len(data)):\n",
        "        if data.iloc[i] > 0:\n",
        "            last_prob = beta * 1 + (1 - beta) * last_prob\n",
        "        else:\n",
        "            last_prob = beta * 0 + (1 - beta) * last_prob\n",
        "    \n",
        "    forecast_demand = avg_size * last_prob\n",
        "    return [forecast_demand] * horizon\n",
        "\n",
        "print(\"‚úÖ –ú–æ–¥–µ–ª–∏ –¥–ª—è intermittent demand –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–æ–¥–µ–ª–∏\n",
        "\n",
        "def linear_regression_forecast(train_data, test_features, calendar_features):\n",
        "    \"\"\"Linear Regression —Å –ª–∞–≥–∞–º–∏ –∏ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\"\"\"\n",
        "    if len(train_data) < 10:\n",
        "        return [train_data.mean()] * len(test_features)\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ –ª–∞–≥–æ–≤\n",
        "    lags = [1, 7, 14, 30]\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    \n",
        "    for i in range(max(lags), len(train_data)):\n",
        "        features = []\n",
        "        # –õ–∞–≥–∏\n",
        "        for lag in lags:\n",
        "            if i - lag >= 0:\n",
        "                features.append(train_data.iloc[i - lag])\n",
        "            else:\n",
        "                features.append(0)\n",
        "        # –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "        if calendar_features is not None and i < len(calendar_features):\n",
        "            cal_features = calendar_features.iloc[i][\n",
        "                ['day_of_week', 'is_weekend', 'month', 'quarter', \n",
        "                 'month_sin', 'month_cos', 'dow_sin', 'dow_cos'] +\n",
        "                ['is_new_year_period', 'is_feb_14_window', 'is_feb_23_window', \n",
        "                 'is_mar_8_window', 'is_black_friday_period']\n",
        "            ].values\n",
        "            features.extend(cal_features)\n",
        "        else:\n",
        "            features.extend([0] * 13)\n",
        "        \n",
        "        X_train.append(features)\n",
        "        y_train.append(train_data.iloc[i])\n",
        "    \n",
        "    if len(X_train) == 0:\n",
        "        return [train_data.mean()] * len(test_features)\n",
        "    \n",
        "    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "    try:\n",
        "        model = LinearRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        # –ü—Ä–æ–≥–Ω–æ–∑\n",
        "        forecast = []\n",
        "        last_values = train_data[-max(lags):].values.tolist()\n",
        "        \n",
        "        for i, test_row in enumerate(test_features.iterrows()):\n",
        "            features = []\n",
        "            # –õ–∞–≥–∏ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
        "            for lag in lags:\n",
        "                if len(last_values) >= lag:\n",
        "                    features.append(last_values[-lag])\n",
        "                else:\n",
        "                    features.append(0)\n",
        "            # –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "            cal_features = test_row[1][\n",
        "                ['day_of_week', 'is_weekend', 'month', 'quarter',\n",
        "                 'month_sin', 'month_cos', 'dow_sin', 'dow_cos'] +\n",
        "                ['is_new_year_period', 'is_feb_14_window', 'is_feb_23_window',\n",
        "                 'is_mar_8_window', 'is_black_friday_period']\n",
        "            ].values\n",
        "            features.extend(cal_features)\n",
        "            \n",
        "            pred = model.predict([features])[0]\n",
        "            forecast.append(max(0, pred))  # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ–º\n",
        "            last_values.append(pred)\n",
        "        return forecast\n",
        "    except:\n",
        "        return [train_data.mean()] * len(test_features)\n",
        "\n",
        "print(\"‚úÖ Linear Regression –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def arima_forecast(data, horizon=30, order=(1, 1, 1)):\n",
        "    \"\"\"ARIMA –º–æ–¥–µ–ª—å\"\"\"\n",
        "    if len(data) < 10:\n",
        "        return [data.mean()] * horizon\n",
        "    \n",
        "    try:\n",
        "        # –£–±–∏—Ä–∞–µ–º –Ω—É–ª–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "        data_clean = data.copy()\n",
        "        data_clean = data_clean.replace(0, 0.01)\n",
        "        \n",
        "        model = ARIMA(data_clean, order=order)\n",
        "        fitted_model = model.fit()\n",
        "        forecast = fitted_model.forecast(steps=horizon)\n",
        "        return [max(0, x) for x in forecast]\n",
        "    except:\n",
        "        return [data.mean()] * horizon\n",
        "\n",
        "def sarima_forecast(data, horizon=30, order=(1, 1, 1), seasonal_order=(1, 1, 1, 7)):\n",
        "    \"\"\"SARIMA –º–æ–¥–µ–ª—å\"\"\"\n",
        "    if len(data) < 20:\n",
        "        return [data.mean()] * horizon\n",
        "    \n",
        "    try:\n",
        "        data_clean = data.copy()\n",
        "        data_clean = data_clean.replace(0, 0.01)\n",
        "        \n",
        "        model = SARIMAX(data_clean, order=order, seasonal_order=seasonal_order)\n",
        "        fitted_model = model.fit(disp=False)\n",
        "        forecast = fitted_model.forecast(steps=horizon)\n",
        "        return [max(0, x) for x in forecast]\n",
        "    except:\n",
        "        return [data.mean()] * horizon\n",
        "\n",
        "def sarimax_forecast(data, exog_train, exog_test, horizon=30):\n",
        "    \"\"\"SARIMAX —Å —ç–∫–∑–æ–≥–µ–Ω–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ (–∫–∞–ª–µ–Ω–¥–∞—Ä—å)\"\"\"\n",
        "    if len(data) < 20 or exog_train is None or exog_test is None:\n",
        "        return [data.mean()] * horizon\n",
        "    \n",
        "    try:\n",
        "        data_clean = data.copy()\n",
        "        data_clean = data_clean.replace(0, 0.01)\n",
        "        \n",
        "        # –í—ã–±–∏—Ä–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "        exog_cols = ['is_weekend', 'month_sin', 'month_cos', \n",
        "                     'is_new_year_period', 'is_black_friday_period']\n",
        "        exog_train_sel = exog_train[exog_cols] if all(c in exog_train.columns for c in exog_cols) else None\n",
        "        exog_test_sel = exog_test[exog_cols] if all(c in exog_test.columns for c in exog_cols) else None\n",
        "        \n",
        "        if exog_train_sel is None or exog_test_sel is None:\n",
        "            return sarima_forecast(data, horizon)\n",
        "        \n",
        "        model = SARIMAX(data_clean, exog=exog_train_sel, \n",
        "                       order=(1, 1, 1), seasonal_order=(1, 1, 1, 7))\n",
        "        fitted_model = model.fit(disp=False)\n",
        "        forecast = fitted_model.forecast(steps=horizon, exog=exog_test_sel)\n",
        "        return [max(0, x) for x in forecast]\n",
        "    except:\n",
        "        return [data.mean()] * horizon\n",
        "\n",
        "print(\"‚úÖ ARIMA/SARIMA/SARIMAX –º–æ–¥–µ–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prophet_forecast(data, dates, horizon_dates, holidays_df=None):\n",
        "    \"\"\"Prophet –º–æ–¥–µ–ª—å —Å –ø—Ä–∞–∑–¥–Ω–∏–∫–∞–º–∏\"\"\"\n",
        "    if len(data) < 30:\n",
        "        return [data.mean()] * len(horizon_dates)\n",
        "    \n",
        "    try:\n",
        "        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Prophet\n",
        "        prophet_data = pd.DataFrame({\n",
        "            'ds': dates,\n",
        "            'y': data.values\n",
        "        })\n",
        "        \n",
        "        # –ü—Ä–∞–∑–¥–Ω–∏–∫–∏ –¥–ª—è Prophet\n",
        "        if holidays_df is None:\n",
        "            holidays_list = []\n",
        "            # –ù–æ–≤—ã–π –≥–æ–¥\n",
        "            for year in [2024, 2025]:\n",
        "                holidays_list.append({'holiday': 'new_year', 'ds': f'{year}-12-31', 'lower_window': -15, 'upper_window': 10})\n",
        "                holidays_list.append({'holiday': 'feb_14', 'ds': f'{year}-02-14', 'lower_window': -7, 'upper_window': 7})\n",
        "                holidays_list.append({'holiday': 'feb_23', 'ds': f'{year}-02-23', 'lower_window': -7, 'upper_window': 7})\n",
        "                holidays_list.append({'holiday': 'mar_8', 'ds': f'{year}-03-08', 'lower_window': -7, 'upper_window': 7})\n",
        "                holidays_list.append({'holiday': 'sep_1', 'ds': f'{year}-09-01', 'lower_window': -7, 'upper_window': 7})\n",
        "            \n",
        "            holidays_df = pd.DataFrame(holidays_list)\n",
        "            holidays_df['ds'] = pd.to_datetime(holidays_df['ds'])\n",
        "        \n",
        "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "        model = Prophet(holidays=holidays_df, yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False)\n",
        "        model.fit(prophet_data)\n",
        "        \n",
        "        # –ü—Ä–æ–≥–Ω–æ–∑\n",
        "        future = pd.DataFrame({'ds': horizon_dates})\n",
        "        forecast = model.predict(future)\n",
        "        \n",
        "        return [max(0, x) for x in forecast['yhat'].values]\n",
        "    except Exception as e:\n",
        "        return [data.mean()] * len(horizon_dates)\n",
        "\n",
        "print(\"‚úÖ Prophet –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏\n",
        "\n",
        "Rolling backtesting —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏: MAE, RMSE, MAPE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\"–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è\"\"\"\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    \n",
        "    # MAE\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    \n",
        "    # RMSE\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    \n",
        "    # MAPE (—É—Å—Ç–æ–π—á–∏–≤—ã–π –∫ –Ω—É–ª—è–º)\n",
        "    mask = y_true > 0\n",
        "    if mask.sum() > 0:\n",
        "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "    else:\n",
        "        mape = 0\n",
        "    \n",
        "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
        "\n",
        "def rolling_backtest(data, calendar_data, models_dict, train_size=180, test_size=30, step=30):\n",
        "    \"\"\"Rolling backtesting –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π\"\"\"\n",
        "    results = []\n",
        "    \n",
        "    if len(data) < train_size + test_size:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    for start_test in range(train_size, len(data) - test_size + 1, step):\n",
        "        train_data = data.iloc[:start_test]\n",
        "        test_data = data.iloc[start_test:start_test + test_size]\n",
        "        \n",
        "        train_calendar = calendar_data.iloc[:start_test] if calendar_data is not None else None\n",
        "        test_calendar = calendar_data.iloc[start_test:start_test + test_size] if calendar_data is not None else None\n",
        "        \n",
        "        for model_name, model_func in models_dict.items():\n",
        "            try:\n",
        "                if model_name == 'Linear Regression':\n",
        "                    forecast = model_func(train_data, test_calendar, train_calendar)\n",
        "                elif model_name == 'SARIMAX':\n",
        "                    forecast = model_func(train_data, train_calendar, test_calendar, len(test_data))\n",
        "                elif model_name == 'Prophet':\n",
        "                    train_dates = train_calendar['–î–∞—Ç–∞'] if train_calendar is not None else pd.date_range('2024-01-01', periods=len(train_data), freq='D')\n",
        "                    test_dates = test_calendar['–î–∞—Ç–∞'] if test_calendar is not None else pd.date_range('2024-01-01', periods=len(test_data), freq='D')\n",
        "                    forecast = model_func(train_data, train_dates, test_dates)\n",
        "                else:\n",
        "                    forecast = model_func(train_data, len(test_data))\n",
        "                \n",
        "                metrics = calculate_metrics(test_data.values, forecast[:len(test_data)])\n",
        "                metrics['model'] = model_name\n",
        "                metrics['fold'] = start_test\n",
        "                results.append(metrics)\n",
        "            except Exception as e:\n",
        "                continue\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ —Ç–æ–≤–∞—Ä–∞\n",
        "example_solo_code = all_solo_codes[0]\n",
        "example_sales = total_sales[total_sales['solo-code'] == example_solo_code].sort_values('–î–∞—Ç–∞')\n",
        "example_calendar = example_sales.copy()\n",
        "\n",
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "sales_series = example_sales['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'].reset_index(drop=True)\n",
        "demand_type = demand_df[demand_df['solo-code'] == example_solo_code]['demand_type'].iloc[0]\n",
        "\n",
        "print(f\"üì¶ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è {example_solo_code}\")\n",
        "print(f\"üìä –¢–∏–ø —Å–ø—Ä–æ—Å–∞: {demand_type}\")\n",
        "print(f\"üìä –î–ª–∏–Ω–∞ —Ä—è–¥–∞: {len(sales_series)}\")\n",
        "\n",
        "# –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å–ø—Ä–æ—Å–∞\n",
        "models_to_test = {}\n",
        "\n",
        "# Baseline –≤—Å–µ–≥–¥–∞\n",
        "models_to_test['Naive'] = lambda data, h: naive_forecast(data, h)\n",
        "models_to_test['Moving Average'] = lambda data, h: moving_average_forecast(data, window=7, horizon=h)\n",
        "models_to_test['Seasonal Naive'] = lambda data, h: seasonal_naive_forecast(data, season_length=7, horizon=h)\n",
        "\n",
        "# –î–ª—è intermittent\n",
        "if demand_type == 'intermittent':\n",
        "    models_to_test['Croston'] = lambda data, h: croston_forecast(data, horizon=h)\n",
        "    models_to_test['SBA'] = lambda data, h: sba_forecast(data, horizon=h)\n",
        "    models_to_test['TSB'] = lambda data, h: tsb_forecast(data, horizon=h)\n",
        "\n",
        "# –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ (–µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö)\n",
        "if len(sales_series) >= 30:\n",
        "    models_to_test['Linear Regression'] = lambda data, cal, cal_train: linear_regression_forecast(data, cal, cal_train)\n",
        "    models_to_test['ARIMA'] = lambda data, h: arima_forecast(data, horizon=h)\n",
        "    \n",
        "if len(sales_series) >= 60:\n",
        "    models_to_test['SARIMA'] = lambda data, h: sarima_forecast(data, horizon=h)\n",
        "    models_to_test['SARIMAX'] = lambda data, exog_train, exog_test, h: sarimax_forecast(data, exog_train, exog_test, h)\n",
        "    \n",
        "if len(sales_series) >= 90:\n",
        "    models_to_test['Prophet'] = lambda data, dates, test_dates: prophet_forecast(data, dates, test_dates)\n",
        "\n",
        "# Backtesting\n",
        "if len(sales_series) >= 180:\n",
        "    backtest_results = rolling_backtest(\n",
        "        sales_series, \n",
        "        example_calendar,\n",
        "        models_to_test,\n",
        "        train_size=120,\n",
        "        test_size=30,\n",
        "        step=30\n",
        "    )\n",
        "    \n",
        "    if len(backtest_results) > 0:\n",
        "        print(\"\\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã backtesting:\")\n",
        "        model_comparison = backtest_results.groupby('model').agg({\n",
        "            'MAE': 'mean',\n",
        "            'RMSE': 'mean',\n",
        "            'MAPE': 'mean'\n",
        "        }).round(2).sort_values('MAE')\n",
        "        print(model_comparison)\n",
        "        \n",
        "        # –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
        "        best_model = model_comparison.index[0]\n",
        "        print(f\"\\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model}\")\n",
        "        print(f\"   MAE: {model_comparison.loc[best_model, 'MAE']:.2f}\")\n",
        "        print(f\"   RMSE: {model_comparison.loc[best_model, 'RMSE']:.2f}\")\n",
        "        print(f\"   MAPE: {model_comparison.loc[best_model, 'MAPE']:.2f}%\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è backtesting\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ backtesting (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 180 –¥–Ω–µ–π)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Rolling-–ø—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ –Ω–∞ 18 –º–µ—Å—è—Ü–µ–≤\n",
        "\n",
        "–°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ solo-code –Ω–∞ 18 –º–µ—Å—è—Ü–µ–≤ –≤–ø–µ—Ä–µ–¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_forecast(solo_code, sales_data, calendar_data, demand_type, models_dict, horizon_months=18):\n",
        "    \"\"\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞\"\"\"\n",
        "    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
        "    item_data = sales_data[sales_data['solo-code'] == solo_code].sort_values('–î–∞—Ç–∞')\n",
        "    item_calendar = calendar_data[calendar_data['solo-code'] == solo_code].sort_values('–î–∞—Ç–∞')\n",
        "    \n",
        "    if len(item_data) == 0:\n",
        "        return None\n",
        "    \n",
        "    sales_series = item_data['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'].reset_index(drop=True)\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
        "    last_date = item_data['–î–∞—Ç–∞'].max()\n",
        "    forecast_dates = pd.date_range(last_date + timedelta(days=1), periods=horizon_months * 30, freq='D')\n",
        "    forecast_calendar = create_calendar_features(pd.DataFrame({'–î–∞—Ç–∞': forecast_dates}))\n",
        "    forecast_calendar = create_holiday_features(forecast_calendar)\n",
        "    forecast_calendar['solo-code'] = solo_code\n",
        "    \n",
        "    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å–ø—Ä–æ—Å–∞ –∏ –¥–ª–∏–Ω—ã –∏—Å—Ç–æ—Ä–∏–∏\n",
        "    selected_model = None\n",
        "    model_name = None\n",
        "    \n",
        "    # –õ–æ–≥–∏–∫–∞ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏\n",
        "    if demand_type == 'intermittent' and len(sales_series) >= 20:\n",
        "        # –î–ª—è –ø—Ä–µ—Ä—ã–≤–∏—Å—Ç–æ–≥–æ —Å–ø—Ä–æ—Å–∞\n",
        "        if 'TSB' in models_dict:\n",
        "            selected_model = lambda: tsb_forecast(sales_series, horizon=len(forecast_dates))\n",
        "            model_name = 'TSB'\n",
        "        elif 'Croston' in models_dict:\n",
        "            selected_model = lambda: croston_forecast(sales_series, horizon=len(forecast_dates))\n",
        "            model_name = 'Croston'\n",
        "        else:\n",
        "            selected_model = lambda: moving_average_forecast(sales_series, horizon=len(forecast_dates))\n",
        "            model_name = 'Moving Average'\n",
        "    elif len(sales_series) >= 90:\n",
        "        # –î–ª—è –¥–ª–∏–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏ - Prophet –∏–ª–∏ SARIMA\n",
        "        if 'Prophet' in models_dict:\n",
        "            train_dates = item_calendar['–î–∞—Ç–∞'].values\n",
        "            selected_model = lambda: prophet_forecast(sales_series, train_dates, forecast_dates)\n",
        "            model_name = 'Prophet'\n",
        "        elif 'SARIMA' in models_dict:\n",
        "            selected_model = lambda: sarima_forecast(sales_series, horizon=len(forecast_dates))\n",
        "            model_name = 'SARIMA'\n",
        "        else:\n",
        "            selected_model = lambda: sarima_forecast(sales_series, horizon=len(forecast_dates))\n",
        "            model_name = 'SARIMA'\n",
        "    elif len(sales_series) >= 30:\n",
        "        # –î–ª—è —Å—Ä–µ–¥–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–∏ - ARIMA –∏–ª–∏ Linear Regression\n",
        "        if 'ARIMA' in models_dict:\n",
        "            selected_model = lambda: arima_forecast(sales_series, horizon=len(forecast_dates))\n",
        "            model_name = 'ARIMA'\n",
        "        elif 'Linear Regression' in models_dict:\n",
        "            selected_model = lambda: linear_regression_forecast(sales_series, forecast_calendar, item_calendar)\n",
        "            model_name = 'Linear Regression'\n",
        "        else:\n",
        "            selected_model = lambda: moving_average_forecast(sales_series, horizon=len(forecast_dates))\n",
        "            model_name = 'Moving Average'\n",
        "    else:\n",
        "        # –î–ª—è –∫–æ—Ä–æ—Ç–∫–æ–π –∏—Å—Ç–æ—Ä–∏–∏ - –ø—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏\n",
        "        selected_model = lambda: moving_average_forecast(sales_series, horizon=len(forecast_dates))\n",
        "        model_name = 'Moving Average'\n",
        "    \n",
        "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
        "    try:\n",
        "        forecast_values = selected_model()\n",
        "        forecast_values = [max(0, x) for x in forecast_values]  # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ–º\n",
        "    except Exception as e:\n",
        "        # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏\n",
        "        forecast_values = moving_average_forecast(sales_series, horizon=len(forecast_dates))\n",
        "        model_name = 'Moving Average (fallback)'\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "    result = pd.DataFrame({\n",
        "        '–î–∞—Ç–∞': forecast_dates[:len(forecast_values)],\n",
        "        'solo-code': solo_code,\n",
        "        '–ü—Ä–æ–≥–Ω–æ–∑': forecast_values,\n",
        "        '–ú–æ–¥–µ–ª—å': model_name\n",
        "    })\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(\"‚úÖ –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤\n",
        "all_forecasts = []\n",
        "\n",
        "print(\"üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤...\")\n",
        "for idx, solo_code in enumerate(all_solo_codes):\n",
        "    if (idx + 1) % 10 == 0:\n",
        "        print(f\"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx + 1}/{len(all_solo_codes)}\")\n",
        "    \n",
        "    demand_type = demand_df[demand_df['solo-code'] == solo_code]['demand_type'].iloc[0]\n",
        "    \n",
        "    # –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Å—É–º–º–∞—Ä–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂\n",
        "    forecast_total = generate_forecast(\n",
        "        solo_code, \n",
        "        total_sales, \n",
        "        total_sales,\n",
        "        demand_type,\n",
        "        models_to_test,\n",
        "        horizon_months=18\n",
        "    )\n",
        "    \n",
        "    if forecast_total is not None:\n",
        "        forecast_total['–ö–∞–Ω–∞–ª'] = 'Total'\n",
        "        all_forecasts.append(forecast_total)\n",
        "    \n",
        "    # –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è WB\n",
        "    forecast_wb = generate_forecast(\n",
        "        solo_code,\n",
        "        wb_sales_processed,\n",
        "        wb_sales_processed,\n",
        "        demand_type,\n",
        "        models_to_test,\n",
        "        horizon_months=18\n",
        "    )\n",
        "    \n",
        "    if forecast_wb is not None:\n",
        "        forecast_wb['–ö–∞–Ω–∞–ª'] = 'WB'\n",
        "        all_forecasts.append(forecast_wb)\n",
        "    \n",
        "    # –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è Ozon\n",
        "    forecast_ozon = generate_forecast(\n",
        "        solo_code,\n",
        "        ozon_sales_processed,\n",
        "        ozon_sales_processed,\n",
        "        demand_type,\n",
        "        models_to_test,\n",
        "        horizon_months=18\n",
        "    )\n",
        "    \n",
        "    if forecast_ozon is not None:\n",
        "        forecast_ozon['–ö–∞–Ω–∞–ª'] = 'Ozon'\n",
        "        all_forecasts.append(forecast_ozon)\n",
        "\n",
        "if all_forecasts:\n",
        "    forecasts_df = pd.concat(all_forecasts, ignore_index=True)\n",
        "    print(f\"\\n‚úÖ –ü—Ä–æ–≥–Ω–æ–∑—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã: {forecasts_df.shape}\")\n",
        "    print(f\"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {forecasts_df['solo-code'].nunique()}\")\n",
        "    print(f\"üìä –ö–∞–Ω–∞–ª–æ–≤: {forecasts_df['–ö–∞–Ω–∞–ª'].unique()}\")\n",
        "    print(f\"\\nüìä –ü—Ä–∏–º–µ—Ä –ø—Ä–æ–≥–Ω–æ–∑–∞:\")\n",
        "    print(forecasts_df.head(10))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è –ü—Ä–æ–≥–Ω–æ–∑—ã –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ —Ç–æ–≤–∞—Ä–∞\n",
        "if 'forecasts_df' in locals() and len(forecasts_df) > 0:\n",
        "    example_solo_code = all_solo_codes[0]\n",
        "    \n",
        "    # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\n",
        "    actual_total = total_sales[total_sales['solo-code'] == example_solo_code].sort_values('–î–∞—Ç–∞')\n",
        "    actual_wb = wb_sales_processed[wb_sales_processed['solo-code'] == example_solo_code].sort_values('–î–∞—Ç–∞')\n",
        "    actual_ozon = ozon_sales_processed[ozon_sales_processed['solo-code'] == example_solo_code].sort_values('–î–∞—Ç–∞')\n",
        "    \n",
        "    # –ü—Ä–æ–≥–Ω–æ–∑—ã\n",
        "    forecast_total = forecasts_df[(forecasts_df['solo-code'] == example_solo_code) & \n",
        "                                  (forecasts_df['–ö–∞–Ω–∞–ª'] == 'Total')].sort_values('–î–∞—Ç–∞')\n",
        "    forecast_wb = forecasts_df[(forecasts_df['solo-code'] == example_solo_code) & \n",
        "                                (forecasts_df['–ö–∞–Ω–∞–ª'] == 'WB')].sort_values('–î–∞—Ç–∞')\n",
        "    forecast_ozon = forecasts_df[(forecasts_df['solo-code'] == example_solo_code) & \n",
        "                                 (forecasts_df['–ö–∞–Ω–∞–ª'] == 'Ozon')].sort_values('–î–∞—Ç–∞')\n",
        "    \n",
        "    fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
        "    \n",
        "    # Total\n",
        "    axes[0].plot(actual_total['–î–∞—Ç–∞'], actual_total['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'], \n",
        "                 label='–§–∞–∫—Ç', linewidth=2, color='blue')\n",
        "    if len(forecast_total) > 0:\n",
        "        axes[0].plot(forecast_total['–î–∞—Ç–∞'], forecast_total['–ü—Ä–æ–≥–Ω–æ–∑'], \n",
        "                    label='–ü—Ä–æ–≥–Ω–æ–∑', linewidth=2, color='red', linestyle='--')\n",
        "        axes[0].axvline(x=actual_total['–î–∞—Ç–∞'].max(), color='gray', linestyle=':', alpha=0.7, label='–ù–∞—á–∞–ª–æ –ø—Ä–æ–≥–Ω–æ–∑–∞')\n",
        "    axes[0].set_title(f'–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂: {example_solo_code} - Total', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('–î–∞—Ç–∞')\n",
        "    axes[0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫–æ–≤–æ–∫')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # WB\n",
        "    axes[1].plot(actual_wb['–î–∞—Ç–∞'], actual_wb['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'], \n",
        "                 label='–§–∞–∫—Ç WB', linewidth=2, color='blue')\n",
        "    if len(forecast_wb) > 0:\n",
        "        axes[1].plot(forecast_wb['–î–∞—Ç–∞'], forecast_wb['–ü—Ä–æ–≥–Ω–æ–∑'], \n",
        "                    label='–ü—Ä–æ–≥–Ω–æ–∑ WB', linewidth=2, color='red', linestyle='--')\n",
        "        axes[1].axvline(x=actual_wb['–î–∞—Ç–∞'].max(), color='gray', linestyle=':', alpha=0.7)\n",
        "    axes[1].set_title(f'–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂: {example_solo_code} - Wildberries', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('–î–∞—Ç–∞')\n",
        "    axes[1].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫–æ–≤–æ–∫')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Ozon\n",
        "    axes[2].plot(actual_ozon['–î–∞—Ç–∞'], actual_ozon['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'], \n",
        "                 label='–§–∞–∫—Ç Ozon', linewidth=2, color='blue')\n",
        "    if len(forecast_ozon) > 0:\n",
        "        axes[2].plot(forecast_ozon['–î–∞—Ç–∞'], forecast_ozon['–ü—Ä–æ–≥–Ω–æ–∑'], \n",
        "                    label='–ü—Ä–æ–≥–Ω–æ–∑ Ozon', linewidth=2, color='red', linestyle='--')\n",
        "        axes[2].axvline(x=actual_ozon['–î–∞—Ç–∞'].max(), color='gray', linestyle=':', alpha=0.7)\n",
        "    axes[2].set_title(f'–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂: {example_solo_code} - Ozon', fontsize=14, fontweight='bold')\n",
        "    axes[2].set_xlabel('–î–∞—Ç–∞')\n",
        "    axes[2].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫–æ–≤–æ–∫')\n",
        "    axes[2].legend()\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nüìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {forecast_total['–ú–æ–¥–µ–ª—å'].iloc[0] if len(forecast_total) > 0 else 'N/A'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. –†–∞—Å—á–µ—Ç —Å—Ç—Ä–∞—Ö–æ–≤–æ–≥–æ –∑–∞–ø–∞—Å–∞\n",
        "\n",
        "–§–æ—Ä–º—É–ª–∞: Safety Stock = Z * œÉ * sqrt(lead_time)\n",
        "\n",
        "–≥–¥–µ:\n",
        "- Z = 1.65 –¥–ª—è service level 95%\n",
        "- œÉ = —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–Ω–µ–≤–Ω–æ–≥–æ —Å–ø—Ä–æ—Å–∞\n",
        "- lead_time = –≤—Ä–µ–º—è –ø–æ—Å—Ç–∞–≤–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 30 –¥–Ω–µ–π)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_safety_stock(sales_data, service_level=0.95, lead_time=30):\n",
        "    \"\"\"–†–∞—Å—á–µ—Ç —Å—Ç—Ä–∞—Ö–æ–≤–æ–≥–æ –∑–∞–ø–∞—Å–∞ –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤\"\"\"\n",
        "    # Z-score –¥–ª—è service level\n",
        "    from scipy import stats\n",
        "    z_score = stats.norm.ppf(service_level)\n",
        "    \n",
        "    safety_stocks = []\n",
        "    \n",
        "    for solo_code in all_solo_codes:\n",
        "        item_data = sales_data[sales_data['solo-code'] == solo_code].sort_values('–î–∞—Ç–∞')\n",
        "        \n",
        "        if len(item_data) == 0:\n",
        "            continue\n",
        "        \n",
        "        demand = item_data['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–∞–∫.'].values\n",
        "        \n",
        "        # –°—Ä–µ–¥–Ω–∏–π –¥–Ω–µ–≤–Ω–æ–π —Å–ø—Ä–æ—Å\n",
        "        mean_demand = np.mean(demand)\n",
        "        \n",
        "        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–Ω–µ–≤–Ω–æ–≥–æ —Å–ø—Ä–æ—Å–∞\n",
        "        std_demand = np.std(demand)\n",
        "        \n",
        "        # –°—Ç—Ä–∞—Ö–æ–≤–æ–π –∑–∞–ø–∞—Å\n",
        "        safety_stock = z_score * std_demand * np.sqrt(lead_time)\n",
        "        safety_stock = max(0, safety_stock)  # –ù–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º\n",
        "        \n",
        "        safety_stocks.append({\n",
        "            'solo-code': solo_code,\n",
        "            'mean_demand': mean_demand,\n",
        "            'std_demand': std_demand,\n",
        "            'safety_stock': safety_stock,\n",
        "            'lead_time': lead_time,\n",
        "            'service_level': service_level\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(safety_stocks)\n",
        "\n",
        "# –†–∞—Å—á–µ—Ç —Å—Ç—Ä–∞—Ö–æ–≤–æ–≥–æ –∑–∞–ø–∞—Å–∞\n",
        "safety_stock_df = calculate_safety_stock(total_sales, service_level=0.95, lead_time=30)\n",
        "\n",
        "print(\"üìä –°—Ç—Ä–∞—Ö–æ–≤–æ–π –∑–∞–ø–∞—Å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω:\")\n",
        "print(safety_stock_df.head(10))\n",
        "print(f\"\\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
        "print(safety_stock_df[['mean_demand', 'std_demand', 'safety_stock']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≥—Ä—É–∑–æ–∫\n",
        "\n",
        "–ù–∞ –æ—Å–Ω–æ–≤–µ:\n",
        "- –ü—Ä–æ–≥–Ω–æ–∑–∞ –ø—Ä–æ–¥–∞–∂\n",
        "- –û—Å—Ç–∞—Ç–∫–æ–≤ –Ω–∞ —Å–∫–ª–∞–¥–∞—Ö (WB, Ozon, –Ω–∞—à —Å–∫–ª–∞–¥)\n",
        "- –°—Ç—Ä–∞—Ö–æ–≤–æ–≥–æ –∑–∞–ø–∞—Å–∞\n",
        "- –ö–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É–ø–∞–∫–æ–≤–æ–∫ –≤ –∫–æ—Ä–æ–±–µ (count_box)\n",
        "\n",
        "–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º:\n",
        "- –ß–∏—Å—Ç—É—é –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å\n",
        "- –û—Ç–≥—Ä—É–∑–∫—É –≤ —É–ø–∞–∫–æ–≤–∫–∞—Ö –∏ –∫–æ—Ä–æ–±–∞—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plan_shipments(forecasts_df, stocks_wb, stocks_ozon, stocks_our, safety_stock_df, count_box_df, horizon_days=30):\n",
        "    \"\"\"–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≥—Ä—É–∑–æ–∫\"\"\"\n",
        "    shipment_plan = []\n",
        "    \n",
        "    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è count_box\n",
        "    count_box_dict = dict(zip(count_box_df['solo-code'], count_box_df['–ö–æ–ª-–≤–æ']))\n",
        "    \n",
        "    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–∏\n",
        "    last_date = max(\n",
        "        stocks_wb['–î–∞—Ç–∞'].max(),\n",
        "        stocks_ozon['–î–∞—Ç–∞'].max(),\n",
        "        stocks_our['–î–∞—Ç–∞'].max()\n",
        "    )\n",
        "    \n",
        "    last_stocks_wb = stocks_wb[stocks_wb['–î–∞—Ç–∞'] == last_date].set_index('solo-code')['–û—Å—Ç–∞—Ç–æ–∫'].to_dict()\n",
        "    last_stocks_ozon = stocks_ozon[stocks_ozon['–î–∞—Ç–∞'] == last_date].set_index('solo-code')['–û—Å—Ç–∞—Ç–æ–∫'].to_dict()\n",
        "    last_stocks_our = stocks_our[stocks_our['–î–∞—Ç–∞'] == last_date].set_index('solo-code')['–û—Å—Ç–∞—Ç–æ–∫'].to_dict()\n",
        "    \n",
        "    # –°–ª–æ–≤–∞—Ä—å —Å—Ç—Ä–∞—Ö–æ–≤–æ–≥–æ –∑–∞–ø–∞—Å–∞\n",
        "    safety_stock_dict = dict(zip(safety_stock_df['solo-code'], safety_stock_df['safety_stock']))\n",
        "    \n",
        "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø–æ –∫–∞–Ω–∞–ª–∞–º\n",
        "    for channel in ['WB', 'Ozon']:\n",
        "        channel_forecasts = forecasts_df[\n",
        "            (forecasts_df['–ö–∞–Ω–∞–ª'] == channel) & \n",
        "            (forecasts_df['–î–∞—Ç–∞'] <= last_date + timedelta(days=horizon_days))\n",
        "        ].copy()\n",
        "        \n",
        "        for solo_code in channel_forecasts['solo-code'].unique():\n",
        "            item_forecast = channel_forecasts[channel_forecasts['solo-code'] == solo_code].sort_values('–î–∞—Ç–∞')\n",
        "            \n",
        "            # –¢–µ–∫—É—â–∏–µ –æ—Å—Ç–∞—Ç–∫–∏\n",
        "            stock_wb = last_stocks_wb.get(solo_code, 0)\n",
        "            stock_ozon = last_stocks_ozon.get(solo_code, 0)\n",
        "            stock_our = last_stocks_our.get(solo_code, 0)\n",
        "            \n",
        "            # –°—Ç—Ä–∞—Ö–æ–≤–æ–π –∑–∞–ø–∞—Å\n",
        "            safety_stock = safety_stock_dict.get(solo_code, 0)\n",
        "            \n",
        "            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –∫–æ—Ä–æ–±–µ\n",
        "            boxes_per_pack = count_box_dict.get(solo_code, 1)\n",
        "            \n",
        "            # –ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ –Ω–∞ –ø–µ—Ä–∏–æ–¥\n",
        "            forecast_demand = item_forecast['–ü—Ä–æ–≥–Ω–æ–∑'].sum()\n",
        "            \n",
        "            # –¢–µ–∫—É—â–∏–π –æ—Å—Ç–∞—Ç–æ–∫ –Ω–∞ –∫–∞–Ω–∞–ª–µ\n",
        "            if channel == 'WB':\n",
        "                current_stock = stock_wb\n",
        "            else:\n",
        "                current_stock = stock_ozon\n",
        "            \n",
        "            # –ß–∏—Å—Ç–∞—è –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å = –ø—Ä–æ–≥–Ω–æ–∑ + —Å—Ç—Ä–∞—Ö–æ–≤–æ–π –∑–∞–ø–∞—Å - —Ç–µ–∫—É—â–∏–π –æ—Å—Ç–∞—Ç–æ–∫\n",
        "            net_requirement = forecast_demand + safety_stock - current_stock\n",
        "            net_requirement = max(0, net_requirement)  # –ù–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º\n",
        "            \n",
        "            # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ —Ü–µ–ª–æ–≥–æ –∫–æ—Ä–æ–±–∞\n",
        "            shipment_boxes = np.ceil(net_requirement / boxes_per_pack) if boxes_per_pack > 0 else 0\n",
        "            shipment_packs = shipment_boxes * boxes_per_pack\n",
        "            \n",
        "            shipment_plan.append({\n",
        "                '–î–∞—Ç–∞_–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è': last_date,\n",
        "                'solo-code': solo_code,\n",
        "                '–ö–∞–Ω–∞–ª': channel,\n",
        "                '–ü—Ä–æ–≥–Ω–æ–∑_–ø—Ä–æ–¥–∞–∂': forecast_demand,\n",
        "                '–û—Å—Ç–∞—Ç–æ–∫_WB': stock_wb,\n",
        "                '–û—Å—Ç–∞—Ç–æ–∫_Ozon': stock_ozon,\n",
        "                '–û—Å—Ç–∞—Ç–æ–∫_–Ω–∞—à': stock_our,\n",
        "                '–°—Ç—Ä–∞—Ö–æ–≤–æ–π_–∑–∞–ø–∞—Å': safety_stock,\n",
        "                '–ß–∏—Å—Ç–∞—è_–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å': net_requirement,\n",
        "                '–û—Ç–≥—Ä—É–∑–∫–∞_—É–ø–∞–∫–æ–≤–æ–∫': shipment_packs,\n",
        "                '–û—Ç–≥—Ä—É–∑–∫–∞_–∫–æ—Ä–æ–±–æ–≤': shipment_boxes,\n",
        "                '–£–ø–∞–∫–æ–≤–æ–∫_–≤_–∫–æ—Ä–æ–±–µ': boxes_per_pack\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(shipment_plan)\n",
        "\n",
        "# –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≥—Ä—É–∑–æ–∫\n",
        "if 'forecasts_df' in locals() and len(forecasts_df) > 0:\n",
        "    shipment_plan_df = plan_shipments(\n",
        "        forecasts_df,\n",
        "        wb_stocks_processed,\n",
        "        ozon_stocks_processed,\n",
        "        our_stocks_processed,\n",
        "        safety_stock_df,\n",
        "        count_box,\n",
        "        horizon_days=30\n",
        "    )\n",
        "    \n",
        "    print(\"üì¶ –ü–ª–∞–Ω –æ—Ç–≥—Ä—É–∑–æ–∫ —Å–æ–∑–¥–∞–Ω:\")\n",
        "    print(shipment_plan_df.head(20))\n",
        "    print(f\"\\nüìä –°–≤–æ–¥–∫–∞ –ø–æ –æ—Ç–≥—Ä—É–∑–∫–∞–º:\")\n",
        "    print(shipment_plan_df.groupby('–ö–∞–Ω–∞–ª').agg({\n",
        "        '–û—Ç–≥—Ä—É–∑–∫–∞_—É–ø–∞–∫–æ–≤–æ–∫': 'sum',\n",
        "        '–û—Ç–≥—Ä—É–∑–∫–∞_–∫–æ—Ä–æ–±–æ–≤': 'sum'\n",
        "    }).round(2))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è –ü—Ä–æ–≥–Ω–æ–∑—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø–ª–∞–Ω –æ—Ç–≥—Ä—É–∑–æ–∫ –Ω–µ —Å–æ–∑–¥–∞–Ω\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"üìä –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê –°–ò–°–¢–ï–ú–´ –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nüì¶ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(all_solo_codes)}\")\n",
        "print(f\"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {min_date.date()} - {max_date.date()}\")\n",
        "print(f\"üìÖ –í—Å–µ–≥–æ –¥–Ω–µ–π –≤ –∏—Å—Ç–æ—Ä–∏–∏: {(max_date - min_date).days + 1}\")\n",
        "\n",
        "print(f\"\\nüìä –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–ø—Ä–æ—Å–∞:\")\n",
        "if 'demand_df' in locals():\n",
        "    print(demand_df['demand_type'].value_counts())\n",
        "\n",
        "print(f\"\\nüìà –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:\")\n",
        "if 'forecasts_df' in locals():\n",
        "    model_usage = forecasts_df.groupby('–ú–æ–¥–µ–ª—å').size().sort_values(ascending=False)\n",
        "    print(model_usage)\n",
        "\n",
        "print(f\"\\nüì¶ –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≥—Ä—É–∑–æ–∫:\")\n",
        "if 'shipment_plan_df' in locals():\n",
        "    total_shipment = shipment_plan_df.groupby('–ö–∞–Ω–∞–ª').agg({\n",
        "        '–û—Ç–≥—Ä—É–∑–∫–∞_—É–ø–∞–∫–æ–≤–æ–∫': 'sum',\n",
        "        '–û—Ç–≥—Ä—É–∑–∫–∞_–∫–æ—Ä–æ–±–æ–≤': 'sum',\n",
        "        'solo-code': 'nunique'\n",
        "    })\n",
        "    print(total_shipment)\n",
        "\n",
        "print(f\"\\nüè¨ –°—Ç—Ä–∞—Ö–æ–≤–æ–π –∑–∞–ø–∞—Å:\")\n",
        "if 'safety_stock_df' in locals():\n",
        "    print(f\"  –°—Ä–µ–¥–Ω–∏–π —Å—Ç—Ä–∞—Ö–æ–≤–æ–π –∑–∞–ø–∞—Å: {safety_stock_df['safety_stock'].mean():.2f} —É–ø–∞–∫–æ–≤–æ–∫\")\n",
        "    print(f\"  –ú–µ–¥–∏–∞–Ω–Ω—ã–π —Å—Ç—Ä–∞—Ö–æ–≤–æ–π –∑–∞–ø–∞—Å: {safety_stock_df['safety_stock'].median():.2f} —É–ø–∞–∫–æ–≤–æ–∫\")\n",
        "    print(f\"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Å—Ç—Ä–∞—Ö–æ–≤–æ–π –∑–∞–ø–∞—Å: {safety_stock_df['safety_stock'].max():.2f} —É–ø–∞–∫–æ–≤–æ–∫\")\n",
        "\n",
        "print(\"\\n‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"‚ö†Ô∏è –†–ò–°–ö–ò –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nüî¥ –†–ò–°–ö–ò:\")\n",
        "print(\"1. –ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –¥–ª–∏–Ω—ã –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö\")\n",
        "print(\"   - –î–ª—è —Ç–æ–≤–∞—Ä–æ–≤ —Å –∫–æ—Ä–æ—Ç–∫–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π (<30 –¥–Ω–µ–π) –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏\")\n",
        "print(\"   - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –Ω–∞–∫–∞–ø–ª–∏–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –º–∏–Ω–∏–º—É–º 3-6 –º–µ—Å—è—Ü–µ–≤\")\n",
        "print(\"\\n2. –ü—Ä–µ—Ä—ã–≤–∏—Å—Ç—ã–π —Å–ø—Ä–æ—Å (intermittent) —Å–ª–æ–∂–µ–Ω –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è\")\n",
        "print(\"   - –í—ã—Å–æ–∫–∞—è –¥–æ–ª—è –Ω—É–ª–µ–≤—ã—Ö –¥–Ω–µ–π —Å–Ω–∏–∂–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å\")\n",
        "print(\"   - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (Croston, TSB)\")\n",
        "print(\"\\n3. –í–Ω–µ—à–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –Ω–µ —É—á—Ç–µ–Ω—ã\")\n",
        "print(\"   - –ü—Ä–æ–º–æ–∞–∫—Ü–∏–∏, –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω, –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞—è —Å—Ä–µ–¥–∞\")\n",
        "print(\"   - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –¥–æ–±–∞–≤–∏—Ç—å –≤–Ω–µ—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏\")\n",
        "print(\"\\n4. –î–µ—Ñ–µ–∫—Ç—É—Ä–∞ –∏ –≤—ã–≤–æ–¥ —Ç–æ–≤–∞—Ä–æ–≤\")\n",
        "print(\"   - –ú–æ–≥—É—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤–ª–∏—è—Ç—å –Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑\")\n",
        "print(\"   - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: —Ä–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏\")\n",
        "print(\"\\n5. –°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å\")\n",
        "print(\"   - –ú–æ–¥–µ–ª–∏ —É—á–∏—Ç—ã–≤–∞—é—Ç –±–∞–∑–æ–≤—É—é —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, –Ω–æ –º–æ–≥—É—Ç –Ω–µ —É–ª–∞–≤–ª–∏–≤–∞—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\")\n",
        "print(\"   - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –ø–æ–¥ –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–æ–≤–∞—Ä–∞\")\n",
        "\n",
        "print(\"\\nüü¢ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –†–ê–ó–í–ò–¢–ò–Æ:\")\n",
        "print(\"1. –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö\")\n",
        "print(\"   - –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\")\n",
        "print(\"   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ—Å—á–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\")\n",
        "print(\"\\n2. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞\")\n",
        "print(\"   - –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ (MAE, RMSE, MAPE) –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\")\n",
        "print(\"   - –ê–ª–µ—Ä—Ç—ã –ø—Ä–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–∏\")\n",
        "print(\"\\n3. A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π\")\n",
        "print(\"   - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\")\n",
        "print(\"   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\")\n",
        "print(\"\\n4. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏\")\n",
        "print(\"   - –ü—Ä–æ–º–æ–∞–∫—Ü–∏–∏, –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω\")\n",
        "print(\"   - –≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã\")\n",
        "print(\"   - –î–∞–Ω–Ω—ã–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)\")\n",
        "print(\"\\n5. –ú—É–ª—å—Ç–∏—É—Ä–æ–≤–Ω–µ–≤–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ\")\n",
        "print(\"   - –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ —É—Ä–æ–≤–Ω–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ + –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ SKU\")\n",
        "print(\"   - –£—á–µ—Ç –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Ç–æ–≤–∞—Ä–∞–º–∏\")\n",
        "print(\"\\n6. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–ø–∞—Å–æ–≤\")\n",
        "print(\"   - –£—á–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ —Å–∫–ª–∞–¥–∞–º\")\n",
        "print(\"   - –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –æ–±—â–∏—Ö –∑–∞—Ç—Ä–∞—Ç (—Ö—Ä–∞–Ω–µ–Ω–∏–µ + –¥–µ—Ñ–∏—Ü–∏—Ç)\")\n",
        "print(\"\\n7. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ –¥–∞—à–±–æ—Ä–¥—ã\")\n",
        "print(\"   - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\")\n",
        "print(\"   - –ê–Ω–∞–ª–∏–∑ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π\")\n",
        "print(\"   - –ü–ª–∞–Ω—ã –æ—Ç–≥—Ä—É–∑–æ–∫ –≤ —É–¥–æ–±–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ\")\n",
        "\n",
        "print(\"\\n‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
