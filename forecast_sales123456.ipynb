{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Прогнозирование продаж и отгрузок для маркетплейсов\n",
        "\n",
        "Этот notebook содержит полный цикл прогнозирования продаж и расчета отгрузок.\n",
        "\n",
        "**Все классы включены в этот notebook - не требуются внешние модули.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Импорт библиотек\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ИМПОРТ БИБЛИОТЕК\n",
        "# ============================================================================\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Опциональные библиотеки для продвинутых моделей\n",
        "try:\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.feature_selection import SelectKBest, f_regression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "    SKLEARN_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SKLEARN_AVAILABLE = False\n",
        "    print(\"Warning: scikit-learn не установлен. Линейная регрессия недоступна.\")\n",
        "\n",
        "try:\n",
        "    from statsmodels.tsa.arima.model import ARIMA\n",
        "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "    STATSMODELS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    STATSMODELS_AVAILABLE = False\n",
        "    print(\"Warning: statsmodels не установлен. ARIMA модели недоступны.\")\n",
        "\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "    PROPHET_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PROPHET_AVAILABLE = False\n",
        "    print(\"Warning: prophet не установлен. Prophet модель недоступна.\")\n",
        "\n",
        "try:\n",
        "    import holidays\n",
        "    HOLIDAYS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    HOLIDAYS_AVAILABLE = False\n",
        "    print(\"Warning: holidays не установлен. Праздники будут недоступны.\")\n",
        "\n",
        "# Настройка отображения\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "except:\n",
        "    try:\n",
        "        plt.style.use('seaborn')\n",
        "    except:\n",
        "        pass\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✓ Библиотеки загружены\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Определение всех классов\n",
        "\n",
        "Все классы определены ниже. Они будут использоваться в последующих ячейках.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. Класс DataLoader - загрузка данных\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# КЛАСС ДЛЯ ЗАГРУЗКИ ДАННЫХ\n",
        "# ============================================================================\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"Класс для загрузки и предобработки данных\"\"\"\n",
        "    \n",
        "    def __init__(self, data_path: str = \"data\", file_paths: Dict[str, str] = None):\n",
        "        \"\"\"\n",
        "        Инициализация\n",
        "        \n",
        "        Args:\n",
        "            data_path: Путь к папке с данными (если файлы в одной папке)\n",
        "            file_paths: Словарь с путями к отдельным файлам {имя_файла: путь}\n",
        "        \"\"\"\n",
        "        self.data_path = Path(data_path) if data_path else None\n",
        "        self.file_paths = file_paths if file_paths else {}\n",
        "        self.wb_sales = None\n",
        "        self.ozon_sales = None\n",
        "        self.wb_stocks = None\n",
        "        self.ozon_stocks = None\n",
        "        self.our_stocks = None\n",
        "        self.withdraw = None\n",
        "        self.defecture = None\n",
        "        self.historical_shipments = None\n",
        "        \n",
        "    def load_all_data(self) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"Загружает все данные из файлов\"\"\"\n",
        "        data = {}\n",
        "        \n",
        "        # Загрузка продаж\n",
        "        try:\n",
        "            self.wb_sales = self._load_sales(\"wb_sales\")\n",
        "            data['wb_sales'] = self.wb_sales\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка загрузки wb_sales: {e}\")\n",
        "            \n",
        "        try:\n",
        "            self.ozon_sales = self._load_sales(\"ozon_sales\")\n",
        "            data['ozon_sales'] = self.ozon_sales\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка загрузки ozon_sales: {e}\")\n",
        "        \n",
        "        # Загрузка остатков\n",
        "        try:\n",
        "            self.wb_stocks = self._load_stocks(\"wb_stocks\")\n",
        "            data['wb_stocks'] = self.wb_stocks\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка загрузки wb_stocks: {e}\")\n",
        "            \n",
        "        try:\n",
        "            self.ozon_stocks = self._load_stocks(\"ozon_stocks\")\n",
        "            data['ozon_stocks'] = self.ozon_stocks\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка загрузки ozon_stocks: {e}\")\n",
        "        \n",
        "        # Загрузка остатков на нашем складе\n",
        "        try:\n",
        "            self.our_stocks = self._load_our_stocks(\"our_stocks\")\n",
        "            data['our_stocks'] = self.our_stocks\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка загрузки our_stocks: {e}\")\n",
        "        \n",
        "        # Загрузка списка на вывод\n",
        "        try:\n",
        "            self.withdraw = self._load_withdraw(\"withdraw\")\n",
        "            data['withdraw'] = self.withdraw\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка загрузки withdraw: {e}\")\n",
        "        \n",
        "        # Загрузка дефектуры\n",
        "        try:\n",
        "            self.defecture = self._load_defecture(\"defecture\")\n",
        "            data['defecture'] = self.defecture\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка загрузки defecture: {e}\")\n",
        "        \n",
        "        return data\n",
        "    \n",
        "    def _get_file_path(self, filename: str, default_name: str = None) -> Path:\n",
        "        \"\"\"Получает путь к файлу из словаря путей или из папки данных\"\"\"\n",
        "        # Сначала проверяем словарь путей\n",
        "        if filename in self.file_paths:\n",
        "            path = Path(self.file_paths[filename])\n",
        "            if path.exists():\n",
        "                return path\n",
        "            else:\n",
        "                print(f\"⚠ Путь к файлу {filename} указан, но файл не найден: {path}\")\n",
        "        \n",
        "        # Если не указан путь, ищем в папке данных\n",
        "        if self.data_path:\n",
        "            # Пробуем разные расширения\n",
        "            for ext in ['.xlsx', '.xls', '.csv']:\n",
        "                file_path = self.data_path / f\"{default_name or filename}{ext}\"\n",
        "                if file_path.exists():\n",
        "                    return file_path\n",
        "        \n",
        "        # Если ничего не найдено\n",
        "        raise FileNotFoundError(f\"Файл {filename} не найден. Проверьте путь в file_paths или наличие файла в {self.data_path}\")\n",
        "    \n",
        "    def _load_sales(self, filename: str) -> pd.DataFrame:\n",
        "        \"\"\"Загружает данные о продажах\"\"\"\n",
        "        file_path = self._get_file_path(filename, 'wb_sales' if 'wb' in filename else 'ozon_sales')\n",
        "        \n",
        "        # Загружаем Excel файл\n",
        "        if file_path.suffix in ['.xlsx', '.xls']:\n",
        "            df = pd.read_excel(file_path)\n",
        "        elif file_path.suffix == '.csv':\n",
        "            df = pd.read_csv(file_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Неподдерживаемый формат файла: {file_path.suffix}\")\n",
        "        \n",
        "        # Обработка даты\n",
        "        if 'Дата' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(df['Дата'], errors='coerce')\n",
        "        elif 'Годы (Дата)' in df.columns and 'Месяцы (Дата)' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(\n",
        "                df['Годы (Дата)'].astype(str) + '-' + \n",
        "                df['Месяцы (Дата)'].astype(str).str.zfill(2) + '-01',\n",
        "                errors='coerce'\n",
        "            )\n",
        "        \n",
        "        # Переименование колонок\n",
        "        column_mapping = {\n",
        "            'Количество упак.': 'quantity',\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'solo-code': 'solo_code',\n",
        "            'SKU': 'sku',\n",
        "            'Дата': 'date'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        # Группировка по дате и унифицированному коду\n",
        "        if 'quantity' in df.columns and 'unified_code' in df.columns and 'date' in df.columns:\n",
        "            df = df.groupby(['date', 'unified_code']).agg({\n",
        "                'quantity': 'sum',\n",
        "                'sku': 'first',\n",
        "                'solo_code': 'first'\n",
        "            }).reset_index()\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _load_stocks(self, filename: str) -> pd.DataFrame:\n",
        "        \"\"\"Загружает данные об остатках на маркетплейсах\"\"\"\n",
        "        file_path = self._get_file_path(filename, 'wb_stocks' if 'wb' in filename else 'ozon_stocks')\n",
        "        \n",
        "        # Загружаем Excel файл\n",
        "        if file_path.suffix in ['.xlsx', '.xls']:\n",
        "            df = pd.read_excel(file_path)\n",
        "        elif file_path.suffix == '.csv':\n",
        "            df = pd.read_csv(file_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Неподдерживаемый формат файла: {file_path.suffix}\")\n",
        "        \n",
        "        # Обработка даты\n",
        "        if 'Дата' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(df['Дата'], errors='coerce')\n",
        "        elif 'Годы (Дата)' in df.columns and 'Месяцы (Дата)' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(\n",
        "                df['Годы (Дата)'].astype(str) + '-' + \n",
        "                df['Месяцы (Дата)'].astype(str).str.zfill(2) + '-01',\n",
        "                errors='coerce'\n",
        "            )\n",
        "        \n",
        "        # Переименование колонок\n",
        "        column_mapping = {\n",
        "            'Остаток': 'stock',\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'solo-code': 'solo_code',\n",
        "            'SKU': 'sku',\n",
        "            'Склад': 'warehouse',\n",
        "            'Дата': 'date'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _load_our_stocks(self, filename: str) -> pd.DataFrame:\n",
        "        \"\"\"Загружает данные об остатках на нашем складе\"\"\"\n",
        "        file_path = self._get_file_path(filename, 'our_stocks')\n",
        "        \n",
        "        # Загружаем Excel файл\n",
        "        if file_path.suffix in ['.xlsx', '.xls']:\n",
        "            df = pd.read_excel(file_path)\n",
        "        elif file_path.suffix == '.csv':\n",
        "            df = pd.read_csv(file_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Неподдерживаемый формат файла: {file_path.suffix}\")\n",
        "        \n",
        "        # Обработка даты\n",
        "        if 'Дата' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(df['Дата'], errors='coerce')\n",
        "        elif 'Годы (Дата)' in df.columns and 'Месяцы (Дата)' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(\n",
        "                df['Годы (Дата)'].astype(str) + '-' + \n",
        "                df['Месяцы (Дата)'].astype(str).str.zfill(2) + '-01',\n",
        "                errors='coerce'\n",
        "            )\n",
        "        \n",
        "        # Переименование колонок\n",
        "        column_mapping = {\n",
        "            'Остаток': 'stock',\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'SKU': 'sku',\n",
        "            'Дата': 'date'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _load_withdraw(self, filename: str) -> pd.DataFrame:\n",
        "        \"\"\"Загружает список продуктов на вывод\"\"\"\n",
        "        try:\n",
        "            file_path = self._get_file_path(filename, 'withdraw')\n",
        "            \n",
        "            # Загружаем Excel файл\n",
        "            if file_path.suffix in ['.xlsx', '.xls']:\n",
        "                df = pd.read_excel(file_path)\n",
        "            elif file_path.suffix == '.csv':\n",
        "                df = pd.read_csv(file_path)\n",
        "            else:\n",
        "                return pd.DataFrame(columns=['unified_code', 'sku'])\n",
        "        except FileNotFoundError:\n",
        "            return pd.DataFrame(columns=['unified_code', 'sku'])\n",
        "        \n",
        "        column_mapping = {\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'SKU': 'sku'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _load_defecture(self, filename: str) -> pd.DataFrame:\n",
        "        \"\"\"Загружает список продуктов в дефектуре\"\"\"\n",
        "        try:\n",
        "            file_path = self._get_file_path(filename, 'defecture')\n",
        "            \n",
        "            # Загружаем Excel файл\n",
        "            if file_path.suffix in ['.xlsx', '.xls']:\n",
        "                df = pd.read_excel(file_path)\n",
        "            elif file_path.suffix == '.csv':\n",
        "                df = pd.read_csv(file_path)\n",
        "            else:\n",
        "                return pd.DataFrame(columns=['unified_code', 'sku', 'end_date'])\n",
        "        except FileNotFoundError:\n",
        "            return pd.DataFrame(columns=['unified_code', 'sku', 'end_date'])\n",
        "        \n",
        "        column_mapping = {\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'SKU': 'sku',\n",
        "            'Дата окончания дефектуры': 'end_date'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        if 'end_date' in df.columns:\n",
        "            df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def load_historical_shipments(self, file_path: str = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Загружает исторические данные отгрузок\n",
        "        \n",
        "        Args:\n",
        "            file_path: Полный путь к файлу с историческими отгрузками\n",
        "        \"\"\"\n",
        "        # Если передан путь, используем его\n",
        "        if file_path:\n",
        "            path = Path(file_path)\n",
        "            if not path.exists():\n",
        "                print(f\"⚠ Файл не найден: {path}\")\n",
        "                return pd.DataFrame()\n",
        "        # Иначе ищем в словаре путей\n",
        "        elif 'historical_shipments' in self.file_paths:\n",
        "            path = Path(self.file_paths['historical_shipments'])\n",
        "            if not path.exists():\n",
        "                print(f\"⚠ Файл не найден: {path}\")\n",
        "                return pd.DataFrame()\n",
        "        # Или в папке данных\n",
        "        elif self.data_path:\n",
        "            path = None\n",
        "            for ext in ['.xlsx', '.xls', '.csv']:\n",
        "                test_path = self.data_path / f\"Отгрузки в МП{ext}\"\n",
        "                if test_path.exists():\n",
        "                    path = test_path\n",
        "                    break\n",
        "            if not path:\n",
        "                print(f\"⚠ Файл 'Отгрузки в МП' не найден в {self.data_path}\")\n",
        "                return pd.DataFrame()\n",
        "        else:\n",
        "            print(\"⚠ Не указан путь к файлу исторических отгрузок\")\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        # Загружаем файл\n",
        "        if path.suffix in ['.xlsx', '.xls']:\n",
        "            df = pd.read_excel(path)\n",
        "        elif path.suffix == '.csv':\n",
        "            df = pd.read_csv(path)\n",
        "        else:\n",
        "            print(f\"⚠ Неподдерживаемый формат файла: {path.suffix}\")\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        # Обработка даты\n",
        "        if 'Дата' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(df['Дата'], errors='coerce')\n",
        "        \n",
        "        # Переименование колонок\n",
        "        column_mapping = {\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'Кол-во упаково': 'quantity',\n",
        "            'Дата': 'date'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        # Группировка по дате и продукту\n",
        "        if 'quantity' in df.columns and 'unified_code' in df.columns and 'date' in df.columns:\n",
        "            df = df.groupby(['date', 'unified_code']).agg({\n",
        "                'quantity': 'sum'\n",
        "            }).reset_index()\n",
        "        \n",
        "        self.historical_shipments = df\n",
        "        return df\n",
        "    \n",
        "    def prepare_sales_data(self, marketplace: str = 'wb') -> pd.DataFrame:\n",
        "        \"\"\"Подготавливает данные о продажах для прогнозирования\"\"\"\n",
        "        if marketplace == 'wb':\n",
        "            sales_df = self.wb_sales.copy() if self.wb_sales is not None else pd.DataFrame()\n",
        "        else:\n",
        "            sales_df = self.ozon_sales.copy() if self.ozon_sales is not None else pd.DataFrame()\n",
        "        \n",
        "        if sales_df.empty:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        sales_df = sales_df.sort_values(['unified_code', 'date'])\n",
        "        return sales_df\n",
        "    \n",
        "    def _process_sales_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Обрабатывает сырые данные о продажах\"\"\"\n",
        "        df = df.copy()\n",
        "        \n",
        "        # Обработка даты\n",
        "        if 'Дата' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(df['Дата'], errors='coerce')\n",
        "        elif 'Годы (Дата)' in df.columns and 'Месяцы (Дата)' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(\n",
        "                df['Годы (Дата)'].astype(str) + '-' + \n",
        "                df['Месяцы (Дата)'].astype(str).str.zfill(2) + '-01',\n",
        "                errors='coerce'\n",
        "            )\n",
        "        \n",
        "        # Переименование колонок\n",
        "        column_mapping = {\n",
        "            'Количество упак.': 'quantity',\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'solo-code': 'solo_code',\n",
        "            'SKU': 'sku',\n",
        "            'Дата': 'date'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        # Группировка по дате и унифицированному коду\n",
        "        if 'quantity' in df.columns and 'unified_code' in df.columns and 'date' in df.columns:\n",
        "            df = df.groupby(['date', 'unified_code']).agg({\n",
        "                'quantity': 'sum',\n",
        "                'sku': 'first',\n",
        "                'solo_code': 'first'\n",
        "            }).reset_index()\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _process_stocks_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Обрабатывает сырые данные об остатках на маркетплейсах\"\"\"\n",
        "        df = df.copy()\n",
        "        \n",
        "        # Обработка даты\n",
        "        if 'Дата' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(df['Дата'], errors='coerce')\n",
        "        elif 'Годы (Дата)' in df.columns and 'Месяцы (Дата)' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(\n",
        "                df['Годы (Дата)'].astype(str) + '-' + \n",
        "                df['Месяцы (Дата)'].astype(str).str.zfill(2) + '-01',\n",
        "                errors='coerce'\n",
        "            )\n",
        "        \n",
        "        # Переименование колонок\n",
        "        column_mapping = {\n",
        "            'Остаток': 'stock',\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'solo-code': 'solo_code',\n",
        "            'SKU': 'sku',\n",
        "            'Склад': 'warehouse',\n",
        "            'Дата': 'date'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _process_our_stocks_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Обрабатывает сырые данные об остатках на нашем складе\"\"\"\n",
        "        df = df.copy()\n",
        "        \n",
        "        # Обработка даты\n",
        "        if 'Дата' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(df['Дата'], errors='coerce')\n",
        "        elif 'Годы (Дата)' in df.columns and 'Месяцы (Дата)' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(\n",
        "                df['Годы (Дата)'].astype(str) + '-' + \n",
        "                df['Месяцы (Дата)'].astype(str).str.zfill(2) + '-01',\n",
        "                errors='coerce'\n",
        "            )\n",
        "        \n",
        "        # Переименование колонок\n",
        "        column_mapping = {\n",
        "            'Остаток': 'stock',\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'SKU': 'sku',\n",
        "            'Дата': 'date'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _process_withdraw_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Обрабатывает сырые данные о продуктах на вывод\"\"\"\n",
        "        df = df.copy()\n",
        "        \n",
        "        column_mapping = {\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'SKU': 'sku'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _process_defecture_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Обрабатывает сырые данные о дефектуре\"\"\"\n",
        "        df = df.copy()\n",
        "        \n",
        "        column_mapping = {\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'SKU': 'sku',\n",
        "            'Дата окончания дефектуры': 'end_date'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        if 'end_date' in df.columns:\n",
        "            df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def _process_historical_shipments_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Обрабатывает сырые данные об исторических отгрузках\"\"\"\n",
        "        df = df.copy()\n",
        "        \n",
        "        # Обработка даты\n",
        "        if 'Дата' in df.columns:\n",
        "            df['Дата'] = pd.to_datetime(df['Дата'], errors='coerce')\n",
        "        \n",
        "        # Переименование колонок\n",
        "        column_mapping = {\n",
        "            'Унифицированный solo-code': 'unified_code',\n",
        "            'Кол-во упаково': 'quantity',\n",
        "            'Дата': 'date'\n",
        "        }\n",
        "        \n",
        "        for old_col, new_col in column_mapping.items():\n",
        "            if old_col in df.columns:\n",
        "                df = df.rename(columns={old_col: new_col})\n",
        "        \n",
        "        # Группировка по дате и продукту\n",
        "        if 'quantity' in df.columns and 'unified_code' in df.columns and 'date' in df.columns:\n",
        "            df = df.groupby(['date', 'unified_code']).agg({\n",
        "                'quantity': 'sum'\n",
        "            }).reset_index()\n",
        "        \n",
        "        return df\n",
        "\n",
        "print(\"✓ Класс DataLoader определен\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. Класс CalendarFeatures - календарные признаки\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# КЛАСС ДЛЯ КАЛЕНДАРНЫХ ПРИЗНАКОВ\n",
        "# ============================================================================\n",
        "\n",
        "class CalendarFeatures:\n",
        "    \"\"\"Класс для создания календарных признаков\"\"\"\n",
        "    \n",
        "    def __init__(self, country='RU'):\n",
        "        self.country = country\n",
        "        if HOLIDAYS_AVAILABLE:\n",
        "            self.ru_holidays = holidays.Russia(years=range(2020, 2030))\n",
        "        else:\n",
        "            self.ru_holidays = {}\n",
        "        \n",
        "        # Даты черной пятницы\n",
        "        self.ozon_black_friday_dates = [\n",
        "            pd.Timestamp('2023-11-24'),\n",
        "            pd.Timestamp('2024-11-29'),\n",
        "            pd.Timestamp('2025-11-28'),\n",
        "        ]\n",
        "        \n",
        "        self.wb_black_friday_dates = [\n",
        "            pd.Timestamp('2023-11-24'),\n",
        "            pd.Timestamp('2024-11-29'),\n",
        "            pd.Timestamp('2025-11-28'),\n",
        "        ]\n",
        "    \n",
        "    def add_calendar_features(self, df: pd.DataFrame, marketplace: str = 'wb') -> pd.DataFrame:\n",
        "        \"\"\"Добавляет календарные признаки к DataFrame\"\"\"\n",
        "        df = df.copy()\n",
        "        \n",
        "        if 'date' not in df.columns:\n",
        "            return df\n",
        "        \n",
        "        # Базовые признаки\n",
        "        df['year'] = df['date'].dt.year\n",
        "        df['month'] = df['date'].dt.month\n",
        "        df['day'] = df['date'].dt.day\n",
        "        df['day_of_week'] = df['date'].dt.dayofweek\n",
        "        df['day_of_year'] = df['date'].dt.dayofyear\n",
        "        df['week_of_year'] = df['date'].dt.isocalendar().week\n",
        "        df['quarter'] = df['date'].dt.quarter\n",
        "        \n",
        "        # Выходные дни\n",
        "        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
        "        \n",
        "        # Праздники\n",
        "        if HOLIDAYS_AVAILABLE:\n",
        "            df['is_holiday'] = df['date'].apply(\n",
        "                lambda x: 1 if x in self.ru_holidays else 0\n",
        "            )\n",
        "        else:\n",
        "            df['is_holiday'] = 0\n",
        "        \n",
        "        # Черная пятница\n",
        "        if marketplace == 'ozon':\n",
        "            black_friday_dates = self.ozon_black_friday_dates\n",
        "        else:\n",
        "            black_friday_dates = self.wb_black_friday_dates\n",
        "        \n",
        "        df['is_black_friday'] = df['date'].apply(\n",
        "            lambda x: 1 if x in black_friday_dates else 0\n",
        "        )\n",
        "        \n",
        "        # Период вокруг черной пятницы\n",
        "        df['is_black_friday_period'] = 0\n",
        "        for bf_date in black_friday_dates:\n",
        "            period_start = bf_date - timedelta(days=7)\n",
        "            period_end = bf_date + timedelta(days=7)\n",
        "            mask = (df['date'] >= period_start) & (df['date'] <= period_end)\n",
        "            df.loc[mask, 'is_black_friday_period'] = 1\n",
        "        \n",
        "        # Новогодние праздники\n",
        "        df['is_new_year_period'] = (\n",
        "            ((df['month'] == 12) & (df['day'] >= 20)) |\n",
        "            ((df['month'] == 1) & (df['day'] <= 10))\n",
        "        ).astype(int)\n",
        "        \n",
        "        # Летний период\n",
        "        df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)\n",
        "        \n",
        "        # Бинарные признаки для месяцев\n",
        "        for month in range(1, 13):\n",
        "            df[f'month_{month}'] = (df['month'] == month).astype(int)\n",
        "        \n",
        "        # Бинарные признаки для дней недели\n",
        "        for day in range(7):\n",
        "            df[f'day_of_week_{day}'] = (df['day_of_week'] == day).astype(int)\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def get_future_calendar_features(self, start_date: pd.Timestamp, \n",
        "                                     periods: int = 18, \n",
        "                                     marketplace: str = 'wb') -> pd.DataFrame:\n",
        "        \"\"\"Создает календарные признаки для будущих дат\"\"\"\n",
        "        dates = pd.date_range(start=start_date, periods=periods * 30, freq='D')\n",
        "        dates = dates[:periods * 30]\n",
        "        \n",
        "        df = pd.DataFrame({'date': dates})\n",
        "        df = self.add_calendar_features(df, marketplace=marketplace)\n",
        "        return df\n",
        "    \n",
        "    def add_black_friday_dates(self, ozon_dates: list, wb_dates: list):\n",
        "        \"\"\"Добавляет даты черной пятницы\"\"\"\n",
        "        self.ozon_black_friday_dates = [pd.Timestamp(d) for d in ozon_dates]\n",
        "        self.wb_black_friday_dates = [pd.Timestamp(d) for d in wb_dates]\n",
        "\n",
        "print(\"✓ Класс CalendarFeatures определен\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. Модели прогнозирования\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# МОДЕЛИ ПРОГНОЗИРОВАНИЯ\n",
        "# ============================================================================\n",
        "\n",
        "# Baseline модель\n",
        "class BaselineModel:\n",
        "    \"\"\"Простая baseline модель\"\"\"\n",
        "    \n",
        "    def __init__(self, method: str = 'mean'):\n",
        "        self.method = method\n",
        "        self.fitted_values = {}\n",
        "    \n",
        "    def fit(self, data: pd.DataFrame, unified_code: str):\n",
        "        if data.empty or 'quantity' not in data.columns:\n",
        "            self.fitted_values[unified_code] = 0\n",
        "            return\n",
        "        \n",
        "        if self.method == 'mean':\n",
        "            value = data['quantity'].mean()\n",
        "        elif self.method == 'median':\n",
        "            value = data['quantity'].median()\n",
        "        elif self.method == 'last':\n",
        "            value = data['quantity'].iloc[-1] if len(data) > 0 else 0\n",
        "        else:\n",
        "            value = data['quantity'].mean()\n",
        "        \n",
        "        self.fitted_values[unified_code] = value if not pd.isna(value) else 0\n",
        "    \n",
        "    def predict(self, unified_code: str, periods: int = 18) -> np.ndarray:\n",
        "        if unified_code not in self.fitted_values:\n",
        "            return np.zeros(periods)\n",
        "        value = self.fitted_values[unified_code]\n",
        "        return np.full(periods, value)\n",
        "    \n",
        "    def get_model_name(self) -> str:\n",
        "        return f\"Baseline ({self.method})\"\n",
        "\n",
        "print(\"✓ BaselineModel определен\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Линейная регрессия\n",
        "if SKLEARN_AVAILABLE:\n",
        "    class LinearRegressionModel:\n",
        "        \"\"\"Линейная регрессия с подбором фичей\"\"\"\n",
        "        \n",
        "        def __init__(self, use_feature_selection: bool = True, k_features: int = 10):\n",
        "            self.use_feature_selection = use_feature_selection\n",
        "            self.k_features = k_features\n",
        "            self.models = {}\n",
        "            self.scalers = {}\n",
        "            self.selected_features = {}\n",
        "            self.feature_names = []\n",
        "        \n",
        "        def fit(self, data: pd.DataFrame, unified_code: str, feature_columns: List[str] = None):\n",
        "            if data.empty or 'quantity' not in data.columns:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            if feature_columns is None:\n",
        "                feature_columns = [col for col in data.columns \n",
        "                                if col not in ['date', 'quantity', 'unified_code', 'sku', 'solo_code']]\n",
        "            \n",
        "            if not feature_columns:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            X = data[feature_columns].fillna(0)\n",
        "            y = data['quantity'].fillna(0)\n",
        "            \n",
        "            if len(X) < 2:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            scaler = StandardScaler()\n",
        "            X_scaled = scaler.fit_transform(X)\n",
        "            self.scalers[unified_code] = scaler\n",
        "            \n",
        "            if self.use_feature_selection and len(feature_columns) > self.k_features:\n",
        "                selector = SelectKBest(f_regression, k=min(self.k_features, len(feature_columns)))\n",
        "                X_selected = selector.fit_transform(X_scaled, y)\n",
        "                self.selected_features[unified_code] = selector.get_support()\n",
        "                selected_feature_names = [feature_columns[i] for i in range(len(feature_columns)) \n",
        "                                        if self.selected_features[unified_code][i]]\n",
        "            else:\n",
        "                X_selected = X_scaled\n",
        "                self.selected_features[unified_code] = np.ones(len(feature_columns), dtype=bool)\n",
        "                selected_feature_names = feature_columns\n",
        "            \n",
        "            self.feature_names = selected_feature_names\n",
        "            \n",
        "            model = LinearRegression()\n",
        "            model.fit(X_selected, y)\n",
        "            self.models[unified_code] = model\n",
        "        \n",
        "        def predict(self, unified_code: str, future_features: pd.DataFrame, periods: int = 18) -> np.ndarray:\n",
        "            if unified_code not in self.models or self.models[unified_code] is None:\n",
        "                return np.zeros(periods)\n",
        "            \n",
        "            if unified_code not in self.scalers:\n",
        "                return np.zeros(periods)\n",
        "            \n",
        "            feature_columns = [col for col in future_features.columns \n",
        "                             if col not in ['date', 'unified_code', 'sku', 'solo_code']]\n",
        "            \n",
        "            if not feature_columns:\n",
        "                return np.zeros(periods)\n",
        "            \n",
        "            X = future_features[feature_columns].fillna(0)\n",
        "            X_scaled = self.scalers[unified_code].transform(X)\n",
        "            \n",
        "            if unified_code in self.selected_features:\n",
        "                X_selected = X_scaled[:, self.selected_features[unified_code]]\n",
        "            else:\n",
        "                X_selected = X_scaled\n",
        "            \n",
        "            predictions = self.models[unified_code].predict(X_selected)\n",
        "            predictions = np.maximum(predictions, 0)\n",
        "            \n",
        "            return predictions[:periods]\n",
        "        \n",
        "        def get_model_name(self) -> str:\n",
        "            return \"Linear Regression (Feature Selection)\" if self.use_feature_selection else \"Linear Regression\"\n",
        "    \n",
        "    class BinaryLinearRegressionModel:\n",
        "        \"\"\"Линейная регрессия с бинарными признаками\"\"\"\n",
        "        \n",
        "        def __init__(self):\n",
        "            self.models = {}\n",
        "            self.scalers = {}\n",
        "            self.feature_names = []\n",
        "        \n",
        "        def fit(self, data: pd.DataFrame, unified_code: str):\n",
        "            if data.empty or 'quantity' not in data.columns:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            binary_features = [col for col in data.columns \n",
        "                              if col.startswith('is_') or \n",
        "                              col.startswith('month_') or \n",
        "                              col.startswith('day_of_week_')]\n",
        "            \n",
        "            if not binary_features:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            X = data[binary_features].fillna(0)\n",
        "            y = data['quantity'].fillna(0)\n",
        "            \n",
        "            if len(X) < 2:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            scaler = StandardScaler()\n",
        "            X_scaled = scaler.fit_transform(X)\n",
        "            self.scalers[unified_code] = scaler\n",
        "            self.feature_names = binary_features\n",
        "            \n",
        "            model = LinearRegression()\n",
        "            model.fit(X_scaled, y)\n",
        "            self.models[unified_code] = model\n",
        "        \n",
        "        def predict(self, unified_code: str, future_features: pd.DataFrame, periods: int = 18) -> np.ndarray:\n",
        "            if unified_code not in self.models or self.models[unified_code] is None:\n",
        "                return np.zeros(periods)\n",
        "            \n",
        "            if unified_code not in self.scalers:\n",
        "                return np.zeros(periods)\n",
        "            \n",
        "            binary_features = [col for col in future_features.columns \n",
        "                              if col.startswith('is_') or \n",
        "                              col.startswith('month_') or \n",
        "                              col.startswith('day_of_week_')]\n",
        "            \n",
        "            if not binary_features:\n",
        "                return np.zeros(periods)\n",
        "            \n",
        "            available_features = [f for f in self.feature_names if f in binary_features]\n",
        "            \n",
        "            if not available_features:\n",
        "                return np.zeros(periods)\n",
        "            \n",
        "            X = future_features[available_features].fillna(0)\n",
        "            \n",
        "            missing_features = [f for f in self.feature_names if f not in available_features]\n",
        "            for feature in missing_features:\n",
        "                X[feature] = 0\n",
        "            \n",
        "            X = X[self.feature_names]\n",
        "            X_scaled = self.scalers[unified_code].transform(X)\n",
        "            predictions = self.models[unified_code].predict(X_scaled)\n",
        "            predictions = np.maximum(predictions, 0)\n",
        "            \n",
        "            return predictions[:periods]\n",
        "        \n",
        "        def get_model_name(self) -> str:\n",
        "            return \"Linear Regression (Binary Features)\"\n",
        "    \n",
        "    print(\"✓ LinearRegressionModel и BinaryLinearRegressionModel определены\")\n",
        "else:\n",
        "    print(\"⚠ LinearRegressionModel недоступны (scikit-learn не установлен)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ARIMA модели\n",
        "if STATSMODELS_AVAILABLE:\n",
        "    class ARIMAModel:\n",
        "        \"\"\"ARIMA модель прогнозирования\"\"\"\n",
        "        \n",
        "        def __init__(self, order: Tuple[int, int, int] = (1, 1, 1), \n",
        "                     seasonal_order: Tuple[int, int, int, int] = None):\n",
        "            self.order = order\n",
        "            self.seasonal_order = seasonal_order\n",
        "            self.models = {}\n",
        "            self.is_sarima = seasonal_order is not None\n",
        "        \n",
        "        def fit(self, data: pd.DataFrame, unified_code: str):\n",
        "            if data.empty or 'quantity' not in data.columns:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            if len(data) < max(self.order) + 1:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            try:\n",
        "                ts = data['quantity'].fillna(0).values\n",
        "                \n",
        "                if self.is_sarima:\n",
        "                    model = SARIMAX(ts, order=self.order, seasonal_order=self.seasonal_order)\n",
        "                else:\n",
        "                    model = ARIMA(ts, order=self.order)\n",
        "                \n",
        "                fitted_model = model.fit(disp=False)\n",
        "                self.models[unified_code] = fitted_model\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка обучения ARIMA для {unified_code}: {e}\")\n",
        "                self.models[unified_code] = None\n",
        "        \n",
        "        def predict(self, unified_code: str, periods: int = 18) -> np.ndarray:\n",
        "            if unified_code not in self.models or self.models[unified_code] is None:\n",
        "                return np.zeros(periods)\n",
        "            \n",
        "            try:\n",
        "                forecast = self.models[unified_code].forecast(steps=periods)\n",
        "                forecast = np.maximum(forecast, 0)\n",
        "                return forecast\n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка прогноза ARIMA для {unified_code}: {e}\")\n",
        "                return np.zeros(periods)\n",
        "        \n",
        "        def get_model_name(self) -> str:\n",
        "            if self.is_sarima:\n",
        "                return f\"SARIMA{self.order}x{self.seasonal_order}\"\n",
        "            return f\"ARIMA{self.order}\"\n",
        "    \n",
        "    class SARIMAXModel:\n",
        "        \"\"\"SARIMAX модель с экзогенными переменными\"\"\"\n",
        "        \n",
        "        def __init__(self, order: Tuple[int, int, int] = (1, 1, 1),\n",
        "                     seasonal_order: Tuple[int, int, int, int] = (1, 1, 1, 12)):\n",
        "            self.order = order\n",
        "            self.seasonal_order = seasonal_order\n",
        "            self.models = {}\n",
        "            self.exog_columns = []\n",
        "        \n",
        "        def fit(self, data: pd.DataFrame, unified_code: str, exog_columns: list = None):\n",
        "            if data.empty or 'quantity' not in data.columns:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            if len(data) < max(self.order) + max(self.seasonal_order[:3]) + 1:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            try:\n",
        "                ts = data['quantity'].fillna(0).values\n",
        "                \n",
        "                if exog_columns:\n",
        "                    exog = data[exog_columns].fillna(0).values\n",
        "                    self.exog_columns = exog_columns\n",
        "                else:\n",
        "                    exog = None\n",
        "                    self.exog_columns = []\n",
        "                \n",
        "                model = SARIMAX(ts, exog=exog, order=self.order, \n",
        "                              seasonal_order=self.seasonal_order)\n",
        "                fitted_model = model.fit(disp=False)\n",
        "                self.models[unified_code] = fitted_model\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка обучения SARIMAX для {unified_code}: {e}\")\n",
        "                self.models[unified_code] = None\n",
        "        \n",
        "        def predict(self, unified_code: str, future_exog: pd.DataFrame = None, \n",
        "                    periods: int = 18) -> np.ndarray:\n",
        "            if unified_code not in self.models or self.models[unified_code] is None:\n",
        "                return np.zeros(periods)\n",
        "            \n",
        "            try:\n",
        "                if self.exog_columns and future_exog is not None:\n",
        "                    exog = future_exog[self.exog_columns].fillna(0).values[:periods]\n",
        "                else:\n",
        "                    exog = None\n",
        "                \n",
        "                forecast = self.models[unified_code].forecast(steps=periods, exog=exog)\n",
        "                forecast = np.maximum(forecast, 0)\n",
        "                return forecast\n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка прогноза SARIMAX для {unified_code}: {e}\")\n",
        "                return np.zeros(periods)\n",
        "        \n",
        "        def get_model_name(self) -> str:\n",
        "            return f\"SARIMAX{self.order}x{self.seasonal_order}\"\n",
        "    \n",
        "    print(\"✓ ARIMAModel и SARIMAXModel определены\")\n",
        "else:\n",
        "    print(\"⚠ ARIMA модели недоступны (statsmodels не установлен)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prophet модель\n",
        "if PROPHET_AVAILABLE:\n",
        "    class ProphetModel:\n",
        "        \"\"\"Prophet модель прогнозирования\"\"\"\n",
        "        \n",
        "        def __init__(self, yearly_seasonality: bool = True,\n",
        "                     weekly_seasonality: bool = True,\n",
        "                     daily_seasonality: bool = False,\n",
        "                     holidays: pd.DataFrame = None):\n",
        "            self.yearly_seasonality = yearly_seasonality\n",
        "            self.weekly_seasonality = weekly_seasonality\n",
        "            self.daily_seasonality = daily_seasonality\n",
        "            self.holidays = holidays\n",
        "            self.models = {}\n",
        "        \n",
        "        def fit(self, data: pd.DataFrame, unified_code: str):\n",
        "            if data.empty or 'quantity' not in data.columns:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            if len(data) < 2:\n",
        "                self.models[unified_code] = None\n",
        "                return\n",
        "            \n",
        "            try:\n",
        "                prophet_data = pd.DataFrame({\n",
        "                    'ds': pd.to_datetime(data['date']),\n",
        "                    'y': data['quantity'].fillna(0).values\n",
        "                })\n",
        "                \n",
        "                model = Prophet(\n",
        "                    yearly_seasonality=self.yearly_seasonality,\n",
        "                    weekly_seasonality=self.weekly_seasonality,\n",
        "                    daily_seasonality=self.daily_seasonality,\n",
        "                    holidays=self.holidays\n",
        "                )\n",
        "                \n",
        "                model.fit(prophet_data)\n",
        "                self.models[unified_code] = model\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка обучения Prophet для {unified_code}: {e}\")\n",
        "                self.models[unified_code] = None\n",
        "        \n",
        "        def predict(self, unified_code: str, periods: int = 18, freq: str = 'D') -> np.ndarray:\n",
        "            if unified_code not in self.models or self.models[unified_code] is None:\n",
        "                return np.zeros(periods)\n",
        "            \n",
        "            try:\n",
        "                if freq == 'D':\n",
        "                    future_periods = periods * 30\n",
        "                else:\n",
        "                    future_periods = periods\n",
        "                \n",
        "                future = self.models[unified_code].make_future_dataframe(\n",
        "                    periods=future_periods, freq=freq\n",
        "                )\n",
        "                \n",
        "                forecast = self.models[unified_code].predict(future)\n",
        "                predictions = forecast['yhat'].tail(future_periods).values\n",
        "                predictions = np.maximum(predictions, 0)\n",
        "                \n",
        "                if freq == 'D' and periods < future_periods:\n",
        "                    monthly_predictions = []\n",
        "                    for i in range(periods):\n",
        "                        start_idx = i * 30\n",
        "                        end_idx = min((i + 1) * 30, len(predictions))\n",
        "                        monthly_predictions.append(predictions[start_idx:end_idx].sum())\n",
        "                    return np.array(monthly_predictions)\n",
        "                \n",
        "                return predictions[:periods]\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка прогноза Prophet для {unified_code}: {e}\")\n",
        "                return np.zeros(periods)\n",
        "        \n",
        "        def get_model_name(self) -> str:\n",
        "            return \"Prophet\"\n",
        "    \n",
        "    print(\"✓ ProphetModel определен\")\n",
        "else:\n",
        "    print(\"⚠ ProphetModel недоступна (prophet не установлен)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4. Вспомогательные классы\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# КЛАСС ДЛЯ ОЦЕНКИ МОДЕЛЕЙ\n",
        "# ============================================================================\n",
        "\n",
        "class ModelEvaluator:\n",
        "    \"\"\"Класс для оценки качества моделей прогнозирования\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.evaluation_results = {}\n",
        "    \n",
        "    def evaluate_model(self, y_true: np.ndarray, y_pred: np.ndarray, \n",
        "                      model_name: str, unified_code: str) -> Dict:\n",
        "        \"\"\"Оценивает качество модели\"\"\"\n",
        "        if len(y_true) == 0 or len(y_pred) == 0:\n",
        "            return {\n",
        "                'mae': np.inf,\n",
        "                'rmse': np.inf,\n",
        "                'mape': np.inf,\n",
        "                'r2': -np.inf\n",
        "            }\n",
        "        \n",
        "        min_len = min(len(y_true), len(y_pred))\n",
        "        y_true = y_true[:min_len]\n",
        "        y_pred = y_pred[:min_len]\n",
        "        \n",
        "        mask = np.isfinite(y_true) & np.isfinite(y_pred) & (y_true > 0)\n",
        "        if mask.sum() == 0:\n",
        "            return {\n",
        "                'mae': np.inf,\n",
        "                'rmse': np.inf,\n",
        "                'mape': np.inf,\n",
        "                'r2': -np.inf\n",
        "            }\n",
        "        \n",
        "        y_true_filtered = y_true[mask]\n",
        "        y_pred_filtered = y_pred[mask]\n",
        "        \n",
        "        mae = mean_absolute_error(y_true_filtered, y_pred_filtered) if SKLEARN_AVAILABLE else np.mean(np.abs(y_true_filtered - y_pred_filtered))\n",
        "        rmse = np.sqrt(mean_squared_error(y_true_filtered, y_pred_filtered)) if SKLEARN_AVAILABLE else np.sqrt(np.mean((y_true_filtered - y_pred_filtered) ** 2))\n",
        "        mape = np.mean(np.abs((y_true_filtered - y_pred_filtered) / y_true_filtered)) * 100\n",
        "        \n",
        "        ss_res = np.sum((y_true_filtered - y_pred_filtered) ** 2)\n",
        "        ss_tot = np.sum((y_true_filtered - np.mean(y_true_filtered)) ** 2)\n",
        "        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else -np.inf\n",
        "        \n",
        "        results = {\n",
        "            'mae': mae,\n",
        "            'rmse': rmse,\n",
        "            'mape': mape,\n",
        "            'r2': r2,\n",
        "            'model_name': model_name,\n",
        "            'unified_code': unified_code\n",
        "        }\n",
        "        \n",
        "        key = f\"{unified_code}_{model_name}\"\n",
        "        self.evaluation_results[key] = results\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def cross_validate(self, data: pd.DataFrame, model, unified_code: str,\n",
        "                      train_size: float = 0.8) -> Dict:\n",
        "        \"\"\"Кросс-валидация модели на исторических данных\"\"\"\n",
        "        if data.empty or len(data) < 10:\n",
        "            return {\n",
        "                'mae': np.inf,\n",
        "                'rmse': np.inf,\n",
        "                'mape': np.inf,\n",
        "                'r2': -np.inf\n",
        "            }\n",
        "        \n",
        "        split_idx = int(len(data) * train_size)\n",
        "        train_data = data.iloc[:split_idx].copy()\n",
        "        test_data = data.iloc[split_idx:].copy()\n",
        "        \n",
        "        if len(test_data) == 0:\n",
        "            return {\n",
        "                'mae': np.inf,\n",
        "                'rmse': np.inf,\n",
        "                'mape': np.inf,\n",
        "                'r2': -np.inf\n",
        "            }\n",
        "        \n",
        "        try:\n",
        "            model.fit(train_data, unified_code)\n",
        "            \n",
        "            if hasattr(model, 'predict'):\n",
        "                periods = len(test_data)\n",
        "                if hasattr(model, 'predict') and len(test_data) > 0:\n",
        "                    y_pred = model.predict(unified_code, periods=periods)\n",
        "                else:\n",
        "                    y_pred = model.predict(unified_code, periods=len(test_data))\n",
        "            else:\n",
        "                return {\n",
        "                    'mae': np.inf,\n",
        "                    'rmse': np.inf,\n",
        "                    'mape': np.inf,\n",
        "                    'r2': -np.inf\n",
        "                }\n",
        "            \n",
        "            y_true = test_data['quantity'].values\n",
        "            \n",
        "            return self.evaluate_model(y_true, y_pred, model.get_model_name(), unified_code)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка кросс-валидации для {unified_code}: {e}\")\n",
        "            return {\n",
        "                'mae': np.inf,\n",
        "                'rmse': np.inf,\n",
        "                'mape': np.inf,\n",
        "                'r2': -np.inf\n",
        "            }\n",
        "    \n",
        "    def select_best_model(self, unified_code: str, metric: str = 'mape') -> str:\n",
        "        \"\"\"Выбирает лучшую модель для продукта\"\"\"\n",
        "        product_results = {\n",
        "            k: v for k, v in self.evaluation_results.items()\n",
        "            if k.startswith(f\"{unified_code}_\")\n",
        "        }\n",
        "        \n",
        "        if not product_results:\n",
        "            return None\n",
        "        \n",
        "        if metric in ['mae', 'rmse', 'mape']:\n",
        "            best_key = min(product_results.keys(), \n",
        "                          key=lambda k: product_results[k].get(metric, np.inf))\n",
        "        else:\n",
        "            best_key = max(product_results.keys(),\n",
        "                          key=lambda k: product_results[k].get(metric, -np.inf))\n",
        "        \n",
        "        return product_results[best_key]['model_name']\n",
        "    \n",
        "    def get_evaluation_summary(self) -> pd.DataFrame:\n",
        "        \"\"\"Возвращает сводку по оценке всех моделей\"\"\"\n",
        "        if not self.evaluation_results:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        results_list = []\n",
        "        for key, results in self.evaluation_results.items():\n",
        "            results_list.append(results)\n",
        "        \n",
        "        return pd.DataFrame(results_list)\n",
        "    \n",
        "    def get_best_models_summary(self) -> pd.DataFrame:\n",
        "        \"\"\"Возвращает сводку по лучшим моделям для каждого продукта\"\"\"\n",
        "        if not self.evaluation_results:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        products = set()\n",
        "        for key in self.evaluation_results.keys():\n",
        "            unified_code = key.split('_')[0]\n",
        "            products.add(unified_code)\n",
        "        \n",
        "        best_models = []\n",
        "        for product in products:\n",
        "            best_model = self.select_best_model(product)\n",
        "            if best_model:\n",
        "                key = f\"{product}_{best_model}\"\n",
        "                if key in self.evaluation_results:\n",
        "                    metrics = self.evaluation_results[key].copy()\n",
        "                    metrics['best_model'] = best_model\n",
        "                    best_models.append(metrics)\n",
        "        \n",
        "        return pd.DataFrame(best_models)\n",
        "\n",
        "print(\"✓ Класс ModelEvaluator определен\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# КЛАСС ДЛЯ РАСЧЕТА ОТГРУЗОК\n",
        "# ============================================================================\n",
        "\n",
        "class ShipmentCalculator:\n",
        "    \"\"\"Класс для расчета отгрузок\"\"\"\n",
        "    \n",
        "    def __init__(self, coverage_coefficient: float = 1.5):\n",
        "        self.coverage_coefficient = coverage_coefficient\n",
        "    \n",
        "    def calculate_shipments(self, forecast: pd.DataFrame, \n",
        "                           stocks: pd.DataFrame,\n",
        "                           marketplace: str = 'wb') -> pd.DataFrame:\n",
        "        \"\"\"Рассчитывает отгрузки по складам на основе прогноза продаж\"\"\"\n",
        "        shipments = []\n",
        "        \n",
        "        forecast['year_month'] = forecast['date'].dt.to_period('M')\n",
        "        forecast_monthly = forecast.groupby(['year_month', 'unified_code'])['quantity'].sum().reset_index()\n",
        "        forecast_monthly['date'] = forecast_monthly['year_month'].dt.to_timestamp()\n",
        "        \n",
        "        if not stocks.empty and 'date' in stocks.columns:\n",
        "            latest_date = stocks['date'].max()\n",
        "            latest_stocks = stocks[stocks['date'] == latest_date].copy()\n",
        "        else:\n",
        "            latest_stocks = stocks.copy()\n",
        "        \n",
        "        if not latest_stocks.empty:\n",
        "            stocks_by_product_warehouse = latest_stocks.groupby(\n",
        "                ['unified_code', 'warehouse']\n",
        "            )['stock'].sum().reset_index()\n",
        "        else:\n",
        "            stocks_by_product_warehouse = pd.DataFrame(columns=['unified_code', 'warehouse', 'stock'])\n",
        "        \n",
        "        for _, row in forecast_monthly.iterrows():\n",
        "            date = row['date']\n",
        "            unified_code = row['unified_code']\n",
        "            forecasted_sales_monthly = row['quantity']\n",
        "            \n",
        "            product_stocks = stocks_by_product_warehouse[\n",
        "                stocks_by_product_warehouse['unified_code'] == unified_code\n",
        "            ].copy()\n",
        "            \n",
        "            if product_stocks.empty:\n",
        "                continue\n",
        "            \n",
        "            required_stock_total = forecasted_sales_monthly * self.coverage_coefficient\n",
        "            current_stock_total = product_stocks['stock'].sum()\n",
        "            \n",
        "            if current_stock_total < required_stock_total:\n",
        "                total_shipment_needed = required_stock_total - current_stock_total\n",
        "                \n",
        "                if current_stock_total > 0:\n",
        "                    product_stocks['shipment'] = (\n",
        "                        total_shipment_needed * product_stocks['stock'] / current_stock_total\n",
        "                    )\n",
        "                else:\n",
        "                    n_warehouses = len(product_stocks)\n",
        "                    product_stocks['shipment'] = total_shipment_needed / n_warehouses\n",
        "                \n",
        "                for _, stock_row in product_stocks.iterrows():\n",
        "                    if stock_row['shipment'] > 0:\n",
        "                        shipments.append({\n",
        "                            'date': date,\n",
        "                            'warehouse': stock_row['warehouse'],\n",
        "                            'unified_code': unified_code,\n",
        "                            'forecasted_sales': forecasted_sales_monthly,\n",
        "                            'current_stock': stock_row['stock'],\n",
        "                            'required_stock': required_stock_total,\n",
        "                            'shipment': stock_row['shipment']\n",
        "                        })\n",
        "            else:\n",
        "                for _, stock_row in product_stocks.iterrows():\n",
        "                    warehouse = stock_row['warehouse']\n",
        "                    current_stock = stock_row['stock']\n",
        "                    \n",
        "                    avg_required_per_warehouse = required_stock_total / len(product_stocks)\n",
        "                    if current_stock < avg_required_per_warehouse:\n",
        "                        shipment = avg_required_per_warehouse - current_stock\n",
        "                        shipments.append({\n",
        "                            'date': date,\n",
        "                            'warehouse': warehouse,\n",
        "                            'unified_code': unified_code,\n",
        "                            'forecasted_sales': forecasted_sales_monthly,\n",
        "                            'current_stock': current_stock,\n",
        "                            'required_stock': avg_required_per_warehouse,\n",
        "                            'shipment': shipment\n",
        "                        })\n",
        "        \n",
        "        if not shipments:\n",
        "            return pd.DataFrame(columns=['date', 'warehouse', 'unified_code', 'shipment'])\n",
        "        \n",
        "        result = pd.DataFrame(shipments)\n",
        "        return result\n",
        "    \n",
        "    def analyze_shipment_calculation(self, historical_sales: pd.DataFrame,\n",
        "                                   historical_stocks: pd.DataFrame,\n",
        "                                   historical_shipments: pd.DataFrame = None) -> Dict:\n",
        "        \"\"\"Анализирует исторические данные для понимания логики расчета отгрузок\"\"\"\n",
        "        analysis = {}\n",
        "        \n",
        "        if historical_sales.empty or historical_stocks.empty:\n",
        "            return analysis\n",
        "        \n",
        "        sales_grouped = historical_sales.groupby(['date', 'unified_code'])['quantity'].sum().reset_index()\n",
        "        products = sales_grouped['unified_code'].unique()[:10]\n",
        "        \n",
        "        coverage_ratios = []\n",
        "        \n",
        "        for product in products:\n",
        "            product_sales = sales_grouped[sales_grouped['unified_code'] == product]\n",
        "            product_stocks = historical_stocks[historical_stocks['unified_code'] == product]\n",
        "            \n",
        "            if product_sales.empty or product_stocks.empty:\n",
        "                continue\n",
        "            \n",
        "            common_dates = set(product_sales['date']) & set(product_stocks['date'])\n",
        "            \n",
        "            for date in list(common_dates)[:5]:\n",
        "                sales = product_sales[product_sales['date'] == date]['quantity'].sum()\n",
        "                stocks = product_stocks[product_stocks['date'] == date]['stock'].sum()\n",
        "                \n",
        "                if sales > 0:\n",
        "                    ratio = stocks / sales\n",
        "                    coverage_ratios.append(ratio)\n",
        "        \n",
        "        if coverage_ratios:\n",
        "            analysis['avg_coverage_ratio'] = np.mean(coverage_ratios)\n",
        "            analysis['median_coverage_ratio'] = np.median(coverage_ratios)\n",
        "            analysis['min_coverage_ratio'] = np.min(coverage_ratios)\n",
        "            analysis['max_coverage_ratio'] = np.max(coverage_ratios)\n",
        "        \n",
        "        if historical_shipments is not None and not historical_shipments.empty:\n",
        "            shipments_grouped = historical_shipments.groupby(['date', 'unified_code'])['quantity'].sum().reset_index()\n",
        "            common_dates = set(sales_grouped['date']) & set(shipments_grouped['date'])\n",
        "            \n",
        "            shipment_ratios = []\n",
        "            coverage_from_shipments = []\n",
        "            \n",
        "            for date in list(common_dates)[:20]:\n",
        "                date_sales = sales_grouped[sales_grouped['date'] == date]\n",
        "                date_shipments = shipments_grouped[shipments_grouped['date'] == date]\n",
        "                \n",
        "                common_products = set(date_sales['unified_code']) & set(date_shipments['unified_code'])\n",
        "                \n",
        "                for product in common_products:\n",
        "                    sales = date_sales[date_sales['unified_code'] == product]['quantity'].sum()\n",
        "                    shipments = date_shipments[date_shipments['unified_code'] == product]['quantity'].sum()\n",
        "                    \n",
        "                    if sales > 0:\n",
        "                        ratio = shipments / sales\n",
        "                        shipment_ratios.append(ratio)\n",
        "                    \n",
        "                    if shipments > 0:\n",
        "                        date_stocks = historical_stocks[\n",
        "                            (historical_stocks['date'] == date) & \n",
        "                            (historical_stocks['unified_code'] == product)\n",
        "                        ]\n",
        "                        if not date_stocks.empty:\n",
        "                            total_stock = date_stocks['stock'].sum()\n",
        "                            if sales > 0:\n",
        "                                coverage = (total_stock + shipments) / sales\n",
        "                                coverage_from_shipments.append(coverage)\n",
        "            \n",
        "            if shipment_ratios:\n",
        "                analysis['avg_shipment_ratio'] = np.mean(shipment_ratios)\n",
        "                analysis['median_shipment_ratio'] = np.median(shipment_ratios)\n",
        "            \n",
        "            if coverage_from_shipments:\n",
        "                analysis['avg_coverage_from_shipments'] = np.mean(coverage_from_shipments)\n",
        "                analysis['median_coverage_from_shipments'] = np.median(coverage_from_shipments)\n",
        "        \n",
        "        return analysis\n",
        "    \n",
        "    def set_coverage_coefficient(self, coefficient: float):\n",
        "        \"\"\"Устанавливает коэффициент покрытия\"\"\"\n",
        "        self.coverage_coefficient = coefficient\n",
        "\n",
        "print(\"✓ Класс ShipmentCalculator определен\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# КЛАСС ДЛЯ ПРИМЕНЕНИЯ ОГРАНИЧЕНИЙ\n",
        "# ============================================================================\n",
        "\n",
        "class Constraints:\n",
        "    \"\"\"Класс для применения ограничений\"\"\"\n",
        "    \n",
        "    def __init__(self, box_sizes: Dict[str, int] = None):\n",
        "        self.box_sizes = box_sizes if box_sizes else {}\n",
        "        self.default_box_size = 24\n",
        "    \n",
        "    def apply_withdraw_constraints(self, forecast: pd.DataFrame,\n",
        "                                  withdraw_list: pd.DataFrame,\n",
        "                                  wb_stocks: pd.DataFrame,\n",
        "                                  ozon_stocks: pd.DataFrame,\n",
        "                                  our_stocks: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Применяет ограничения для продуктов на вывод\"\"\"\n",
        "        forecast = forecast.copy()\n",
        "        \n",
        "        if withdraw_list.empty:\n",
        "            return forecast\n",
        "        \n",
        "        withdraw_codes = set(withdraw_list['unified_code'].unique())\n",
        "        latest_wb_stocks = self._get_latest_stocks(wb_stocks)\n",
        "        latest_ozon_stocks = self._get_latest_stocks(ozon_stocks)\n",
        "        latest_our_stocks = self._get_latest_stocks(our_stocks)\n",
        "        \n",
        "        for unified_code in withdraw_codes:\n",
        "            if unified_code not in forecast['unified_code'].values:\n",
        "                continue\n",
        "            \n",
        "            wb_total = latest_wb_stocks.get(unified_code, 0)\n",
        "            ozon_total = latest_ozon_stocks.get(unified_code, 0)\n",
        "            our_total = latest_our_stocks.get(unified_code, 0)\n",
        "            \n",
        "            total_stock = wb_total + ozon_total + our_total\n",
        "            \n",
        "            if total_stock <= 0:\n",
        "                forecast.loc[forecast['unified_code'] == unified_code, 'quantity'] = 0\n",
        "        \n",
        "        return forecast\n",
        "    \n",
        "    def apply_defecture_constraints(self, forecast: pd.DataFrame,\n",
        "                                   defecture_list: pd.DataFrame,\n",
        "                                   wb_stocks: pd.DataFrame,\n",
        "                                   ozon_stocks: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Применяет ограничения для продуктов в дефектуре\"\"\"\n",
        "        forecast = forecast.copy()\n",
        "        \n",
        "        if defecture_list.empty:\n",
        "            return forecast\n",
        "        \n",
        "        latest_wb_stocks = self._get_latest_stocks(wb_stocks)\n",
        "        latest_ozon_stocks = self._get_latest_stocks(ozon_stocks)\n",
        "        \n",
        "        for _, defecture_row in defecture_list.iterrows():\n",
        "            unified_code = defecture_row['unified_code']\n",
        "            end_date = defecture_row.get('end_date', pd.Timestamp.max)\n",
        "            \n",
        "            if unified_code not in forecast['unified_code'].values:\n",
        "                continue\n",
        "            \n",
        "            future_dates = forecast[\n",
        "                (forecast['unified_code'] == unified_code) & \n",
        "                (forecast['date'] > end_date)\n",
        "            ]\n",
        "            \n",
        "            if len(future_dates) == 0:\n",
        "                wb_total = latest_wb_stocks.get(unified_code, 0)\n",
        "                ozon_total = latest_ozon_stocks.get(unified_code, 0)\n",
        "                \n",
        "                total_stock = wb_total + ozon_total\n",
        "                \n",
        "                if total_stock <= 0:\n",
        "                    forecast.loc[forecast['unified_code'] == unified_code, 'quantity'] = 0\n",
        "        \n",
        "        return forecast\n",
        "    \n",
        "    def apply_box_constraints(self, shipments: pd.DataFrame,\n",
        "                             box_sizes: Dict[str, int] = None) -> pd.DataFrame:\n",
        "        \"\"\"Округляет отгрузки до размера короба\"\"\"\n",
        "        shipments = shipments.copy()\n",
        "        \n",
        "        if shipments.empty:\n",
        "            return shipments\n",
        "        \n",
        "        if box_sizes is None:\n",
        "            box_sizes = self.box_sizes\n",
        "        \n",
        "        for idx, row in shipments.iterrows():\n",
        "            unified_code = row['unified_code']\n",
        "            shipment = row['shipment']\n",
        "            \n",
        "            if box_sizes and unified_code in box_sizes:\n",
        "                box_size = box_sizes[unified_code]\n",
        "            elif isinstance(box_sizes, dict) and 'default' in box_sizes:\n",
        "                box_size = box_sizes['default']\n",
        "            else:\n",
        "                box_size = self.default_box_size\n",
        "            \n",
        "            boxes = np.ceil(shipment / box_size)\n",
        "            rounded_shipment = boxes * box_size\n",
        "            \n",
        "            shipments.loc[idx, 'shipment'] = rounded_shipment\n",
        "            shipments.loc[idx, 'boxes'] = boxes\n",
        "        \n",
        "        return shipments\n",
        "    \n",
        "    def apply_shipment_withdraw_constraints(self, shipments: pd.DataFrame,\n",
        "                                          withdraw_list: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Обнуляет отгрузки для продуктов на вывод\"\"\"\n",
        "        shipments = shipments.copy()\n",
        "        \n",
        "        if withdraw_list.empty:\n",
        "            return shipments\n",
        "        \n",
        "        withdraw_codes = set(withdraw_list['unified_code'].unique())\n",
        "        shipments.loc[shipments['unified_code'].isin(withdraw_codes), 'shipment'] = 0\n",
        "        \n",
        "        return shipments\n",
        "    \n",
        "    def apply_shipment_defecture_constraints(self, shipments: pd.DataFrame,\n",
        "                                           defecture_list: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Обнуляет отгрузки для продуктов в дефектуре\"\"\"\n",
        "        shipments = shipments.copy()\n",
        "        \n",
        "        if defecture_list.empty:\n",
        "            return shipments\n",
        "        \n",
        "        defecture_codes = set(defecture_list['unified_code'].unique())\n",
        "        shipments.loc[shipments['unified_code'].isin(defecture_codes), 'shipment'] = 0\n",
        "        \n",
        "        return shipments\n",
        "    \n",
        "    def _get_latest_stocks(self, stocks: pd.DataFrame) -> Dict[str, float]:\n",
        "        \"\"\"Получает последние остатки по продуктам\"\"\"\n",
        "        if stocks.empty:\n",
        "            return {}\n",
        "        \n",
        "        if 'date' in stocks.columns:\n",
        "            latest_date = stocks['date'].max()\n",
        "            latest_stocks = stocks[stocks['date'] == latest_date]\n",
        "        else:\n",
        "            latest_stocks = stocks\n",
        "        \n",
        "        if 'unified_code' in latest_stocks.columns and 'stock' in latest_stocks.columns:\n",
        "            result = latest_stocks.groupby('unified_code')['stock'].sum().to_dict()\n",
        "            return result\n",
        "        \n",
        "        return {}\n",
        "    \n",
        "    def set_box_sizes(self, box_sizes: Dict[str, int]):\n",
        "        \"\"\"Устанавливает размеры коробов\"\"\"\n",
        "        self.box_sizes = box_sizes\n",
        "\n",
        "print(\"✓ Класс Constraints определен\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# КЛАСС ДЛЯ УПРАВЛЕНИЯ ПРОГНОЗАМИ\n",
        "# ============================================================================\n",
        "\n",
        "class ForecastManager:\n",
        "    \"\"\"Класс для управления прогнозами\"\"\"\n",
        "    \n",
        "    def __init__(self, storage_path: str = \"forecast_history\"):\n",
        "        self.storage_path = Path(storage_path)\n",
        "        self.storage_path.mkdir(exist_ok=True)\n",
        "    \n",
        "    def save_forecast(self, forecast: pd.DataFrame, model_name: str,\n",
        "                     marketplace: str, forecast_date: datetime = None,\n",
        "                     metadata: Dict = None):\n",
        "        \"\"\"Сохраняет прогноз в историю\"\"\"\n",
        "        if forecast_date is None:\n",
        "            forecast_date = datetime.now()\n",
        "        \n",
        "        filename = f\"{marketplace}_{model_name}_{forecast_date.strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        filepath = self.storage_path / filename\n",
        "        \n",
        "        forecast.to_csv(filepath, index=False)\n",
        "        \n",
        "        if metadata:\n",
        "            import json\n",
        "            metadata_filename = f\"{marketplace}_{model_name}_{forecast_date.strftime('%Y%m%d_%H%M%S')}_metadata.json\"\n",
        "            metadata_filepath = self.storage_path / metadata_filename\n",
        "            \n",
        "            with open(metadata_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(metadata, f, ensure_ascii=False, indent=2, default=str)\n",
        "    \n",
        "    def load_forecast(self, marketplace: str, model_name: str,\n",
        "                     forecast_date: str = None) -> pd.DataFrame:\n",
        "        \"\"\"Загружает прогноз из истории\"\"\"\n",
        "        if forecast_date:\n",
        "            filename = f\"{marketplace}_{model_name}_{forecast_date}.csv\"\n",
        "        else:\n",
        "            pattern = f\"{marketplace}_{model_name}_*.csv\"\n",
        "            files = list(self.storage_path.glob(pattern))\n",
        "            if not files:\n",
        "                return pd.DataFrame()\n",
        "            filename = max(files, key=lambda p: p.stat().st_mtime).name\n",
        "        \n",
        "        filepath = self.storage_path / filename\n",
        "        if not filepath.exists():\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        return pd.read_csv(filepath)\n",
        "    \n",
        "    def get_forecast_history(self, marketplace: str = None,\n",
        "                            model_name: str = None,\n",
        "                            unified_code: str = None) -> pd.DataFrame:\n",
        "        \"\"\"Получает историю прогнозов\"\"\"\n",
        "        all_forecasts = []\n",
        "        \n",
        "        pattern = \"*_*_*.csv\"\n",
        "        if marketplace:\n",
        "            pattern = f\"{marketplace}_*_*.csv\"\n",
        "        if model_name:\n",
        "            pattern = f\"*_{model_name}_*.csv\"\n",
        "        \n",
        "        files = list(self.storage_path.glob(pattern))\n",
        "        \n",
        "        for filepath in files:\n",
        "            try:\n",
        "                forecast = pd.read_csv(filepath)\n",
        "                \n",
        "                parts = filepath.stem.split('_')\n",
        "                if len(parts) >= 3:\n",
        "                    forecast['marketplace'] = parts[0]\n",
        "                    forecast['model_name'] = parts[1]\n",
        "                    forecast['forecast_date'] = '_'.join(parts[2:])\n",
        "                \n",
        "                all_forecasts.append(forecast)\n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка загрузки {filepath}: {e}\")\n",
        "        \n",
        "        if not all_forecasts:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        result = pd.concat(all_forecasts, ignore_index=True)\n",
        "        \n",
        "        if unified_code:\n",
        "            result = result[result['unified_code'] == unified_code]\n",
        "        \n",
        "        return result\n",
        "\n",
        "print(\"✓ Класс ForecastManager определен\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5. Главный класс SalesForecaster\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ГЛАВНЫЙ КЛАСС ДЛЯ ПРОГНОЗИРОВАНИЯ\n",
        "# ============================================================================\n",
        "\n",
        "class SalesForecaster:\n",
        "    \"\"\"Главный класс для прогнозирования продаж и отгрузок\"\"\"\n",
        "    \n",
        "    def __init__(self, data_path: str = \"data\", forecast_months: int = 18):\n",
        "        self.data_path = data_path\n",
        "        self.forecast_months = forecast_months\n",
        "        \n",
        "        self.data_loader = DataLoader(data_path)\n",
        "        self.calendar_features = CalendarFeatures()\n",
        "        self.evaluator = ModelEvaluator()\n",
        "        self.shipment_calculator = ShipmentCalculator()\n",
        "        self.constraints = Constraints()\n",
        "        self.forecast_manager = ForecastManager()\n",
        "        \n",
        "        self.data = {}\n",
        "        self.models = {}\n",
        "        \n",
        "    def load_data(self):\n",
        "        \"\"\"Загружает все данные\"\"\"\n",
        "        print(\"Загрузка данных...\")\n",
        "        self.data = self.data_loader.load_all_data()\n",
        "        print(\"Данные загружены\")\n",
        "    \n",
        "    def prepare_models(self):\n",
        "        \"\"\"Подготавливает модели для прогнозирования\"\"\"\n",
        "        print(\"Подготовка моделей...\")\n",
        "        \n",
        "        self.models['baseline_mean'] = BaselineModel(method='mean')\n",
        "        self.models['baseline_median'] = BaselineModel(method='median')\n",
        "        self.models['baseline_last'] = BaselineModel(method='last')\n",
        "        \n",
        "        if SKLEARN_AVAILABLE:\n",
        "            self.models['linear_regression'] = LinearRegressionModel(use_feature_selection=True)\n",
        "            self.models['binary_linear_regression'] = BinaryLinearRegressionModel()\n",
        "        \n",
        "        if STATSMODELS_AVAILABLE:\n",
        "            try:\n",
        "                self.models['arima'] = ARIMAModel(order=(1, 1, 1))\n",
        "                self.models['sarima'] = ARIMAModel(\n",
        "                    order=(1, 1, 1),\n",
        "                    seasonal_order=(1, 1, 1, 12)\n",
        "                )\n",
        "                self.models['sarimax'] = SARIMAXModel(\n",
        "                    order=(1, 1, 1),\n",
        "                    seasonal_order=(1, 1, 1, 12)\n",
        "                )\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        if PROPHET_AVAILABLE:\n",
        "            try:\n",
        "                holidays_df = self._prepare_prophet_holidays()\n",
        "                self.models['prophet'] = ProphetModel(holidays=holidays_df)\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        print(f\"Подготовлено {len(self.models)} моделей\")\n",
        "    \n",
        "    def _prepare_prophet_holidays(self) -> pd.DataFrame:\n",
        "        \"\"\"Подготавливает праздники для Prophet\"\"\"\n",
        "        holidays_list = []\n",
        "        \n",
        "        if not HOLIDAYS_AVAILABLE:\n",
        "            return None\n",
        "        \n",
        "        ru_holidays = holidays.Russia(years=range(2020, 2030))\n",
        "        for date, name in ru_holidays.items():\n",
        "            holidays_list.append({\n",
        "                'ds': pd.Timestamp(date),\n",
        "                'holiday': name\n",
        "            })\n",
        "        \n",
        "        for bf_date in self.calendar_features.ozon_black_friday_dates:\n",
        "            holidays_list.append({\n",
        "                'ds': bf_date,\n",
        "                'holiday': 'Black Friday Ozon'\n",
        "            })\n",
        "        \n",
        "        for bf_date in self.calendar_features.wb_black_friday_dates:\n",
        "            holidays_list.append({\n",
        "                'ds': bf_date,\n",
        "                'holiday': 'Black Friday WB'\n",
        "            })\n",
        "        \n",
        "        return pd.DataFrame(holidays_list) if holidays_list else None\n",
        "    \n",
        "    def forecast_sales(self, marketplace: str = 'wb', \n",
        "                      unified_code: str = None,\n",
        "                      evaluate: bool = True) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"Прогнозирует продажи для маркетплейса\"\"\"\n",
        "        print(f\"Прогнозирование продаж для {marketplace}...\")\n",
        "        \n",
        "        sales_data = self.data_loader.prepare_sales_data(marketplace)\n",
        "        if sales_data.empty:\n",
        "            print(f\"Нет данных о продажах для {marketplace}\")\n",
        "            return {}\n",
        "        \n",
        "        if unified_code:\n",
        "            products = [unified_code]\n",
        "        else:\n",
        "            products = sales_data['unified_code'].unique()\n",
        "        \n",
        "        all_forecasts = {}\n",
        "        \n",
        "        for product in products:\n",
        "            print(f\"  Прогнозирование для продукта {product}...\")\n",
        "            \n",
        "            product_data = sales_data[sales_data['unified_code'] == product].copy()\n",
        "            if product_data.empty:\n",
        "                continue\n",
        "            \n",
        "            product_data = self.calendar_features.add_calendar_features(\n",
        "                product_data, marketplace=marketplace\n",
        "            )\n",
        "            \n",
        "            last_date = product_data['date'].max()\n",
        "            future_dates = pd.date_range(\n",
        "                start=last_date + timedelta(days=1),\n",
        "                periods=self.forecast_months * 30,\n",
        "                freq='D'\n",
        "            )[:self.forecast_months * 30]\n",
        "            \n",
        "            future_df = pd.DataFrame({'date': future_dates})\n",
        "            future_df = self.calendar_features.add_calendar_features(\n",
        "                future_df, marketplace=marketplace\n",
        "            )\n",
        "            future_df['unified_code'] = product\n",
        "            \n",
        "            product_forecasts = {}\n",
        "            \n",
        "            for model_name, model in self.models.items():\n",
        "                try:\n",
        "                    if model_name in ['linear_regression', 'binary_linear_regression']:\n",
        "                        model.fit(product_data, product)\n",
        "                        forecast_values = model.predict(product, future_df, periods=len(future_dates))\n",
        "                    elif model_name == 'sarimax':\n",
        "                        exog_cols = [col for col in product_data.columns \n",
        "                                   if col.startswith('is_') or col.startswith('month_')]\n",
        "                        if exog_cols:\n",
        "                            model.fit(product_data, product, exog_columns=exog_cols)\n",
        "                            future_exog = future_df[exog_cols]\n",
        "                            forecast_values = model.predict(product, future_exog, periods=len(future_dates))\n",
        "                        else:\n",
        "                            forecast_values = np.zeros(len(future_dates))\n",
        "                    else:\n",
        "                        model.fit(product_data, product)\n",
        "                        forecast_values = model.predict(product, periods=len(future_dates))\n",
        "                    \n",
        "                    forecast_df = pd.DataFrame({\n",
        "                        'date': future_dates[:len(forecast_values)],\n",
        "                        'unified_code': product,\n",
        "                        'quantity': forecast_values,\n",
        "                        'model_name': model_name\n",
        "                    })\n",
        "                    \n",
        "                    product_forecasts[model_name] = forecast_df\n",
        "                    \n",
        "                    if evaluate and len(product_data) > 10:\n",
        "                        try:\n",
        "                            self.evaluator.cross_validate(\n",
        "                                product_data, model, product\n",
        "                            )\n",
        "                        except Exception as e:\n",
        "                            print(f\"    Ошибка оценки модели {model_name}: {e}\")\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"    Ошибка прогнозирования моделью {model_name} для {product}: {e}\")\n",
        "                    continue\n",
        "            \n",
        "            for model_name, forecast_df in product_forecasts.items():\n",
        "                if model_name not in all_forecasts:\n",
        "                    all_forecasts[model_name] = []\n",
        "                all_forecasts[model_name].append(forecast_df)\n",
        "        \n",
        "        result = {}\n",
        "        for model_name, forecasts_list in all_forecasts.items():\n",
        "            if forecasts_list:\n",
        "                result[model_name] = pd.concat(forecasts_list, ignore_index=True)\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def select_best_forecasts(self, forecasts: Dict[str, pd.DataFrame],\n",
        "                             marketplace: str) -> pd.DataFrame:\n",
        "        \"\"\"Выбирает лучшие прогнозы для каждого продукта\"\"\"\n",
        "        print(\"Выбор лучших прогнозов...\")\n",
        "        \n",
        "        best_forecasts = []\n",
        "        all_products = set()\n",
        "        for forecast_df in forecasts.values():\n",
        "            all_products.update(forecast_df['unified_code'].unique())\n",
        "        \n",
        "        for product in all_products:\n",
        "            best_model = self.evaluator.select_best_model(product, metric='mape')\n",
        "            \n",
        "            if best_model and best_model in forecasts:\n",
        "                product_forecast = forecasts[best_model][\n",
        "                    forecasts[best_model]['unified_code'] == product\n",
        "                ].copy()\n",
        "                product_forecast['selected_model'] = best_model\n",
        "                best_forecasts.append(product_forecast)\n",
        "        \n",
        "        if not best_forecasts:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        return pd.concat(best_forecasts, ignore_index=True)\n",
        "    \n",
        "    def apply_constraints_to_forecast(self, forecast: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Применяет ограничения к прогнозу\"\"\"\n",
        "        print(\"Применение ограничений к прогнозу...\")\n",
        "        \n",
        "        if 'withdraw' in self.data and not self.data['withdraw'].empty:\n",
        "            forecast = self.constraints.apply_withdraw_constraints(\n",
        "                forecast,\n",
        "                self.data['withdraw'],\n",
        "                self.data.get('wb_stocks', pd.DataFrame()),\n",
        "                self.data.get('ozon_stocks', pd.DataFrame()),\n",
        "                self.data.get('our_stocks', pd.DataFrame())\n",
        "            )\n",
        "        \n",
        "        if 'defecture' in self.data and not self.data['defecture'].empty:\n",
        "            forecast = self.constraints.apply_defecture_constraints(\n",
        "                forecast,\n",
        "                self.data['defecture'],\n",
        "                self.data.get('wb_stocks', pd.DataFrame()),\n",
        "                self.data.get('ozon_stocks', pd.DataFrame())\n",
        "            )\n",
        "        \n",
        "        return forecast\n",
        "    \n",
        "    def calculate_shipments(self, forecast: pd.DataFrame,\n",
        "                           marketplace: str = 'wb') -> pd.DataFrame:\n",
        "        \"\"\"Рассчитывает отгрузки на основе прогноза\"\"\"\n",
        "        print(f\"Расчет отгрузок для {marketplace}...\")\n",
        "        \n",
        "        stocks = self.data.get(f'{marketplace}_stocks', pd.DataFrame())\n",
        "        if stocks.empty:\n",
        "            print(f\"Нет данных об остатках для {marketplace}\")\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        forecast_for_shipment = forecast.copy()\n",
        "        if 'date' in forecast_for_shipment.columns:\n",
        "            forecast_for_shipment['date'] = pd.to_datetime(forecast_for_shipment['date'])\n",
        "            forecast_for_shipment['year_month'] = forecast_for_shipment['date'].dt.to_period('M')\n",
        "            forecast_monthly = forecast_for_shipment.groupby(\n",
        "                ['year_month', 'unified_code']\n",
        "            ).agg({\n",
        "                'quantity': 'sum'\n",
        "            }).reset_index()\n",
        "            forecast_monthly['date'] = forecast_monthly['year_month'].dt.to_timestamp()\n",
        "            forecast_for_shipment = forecast_monthly[['date', 'unified_code', 'quantity']]\n",
        "        \n",
        "        shipments = self.shipment_calculator.calculate_shipments(\n",
        "            forecast_for_shipment, stocks, marketplace=marketplace\n",
        "        )\n",
        "        \n",
        "        if 'withdraw' in self.data and not self.data['withdraw'].empty:\n",
        "            shipments = self.constraints.apply_shipment_withdraw_constraints(\n",
        "                shipments, self.data['withdraw']\n",
        "            )\n",
        "        \n",
        "        if 'defecture' in self.data and not self.data['defecture'].empty:\n",
        "            shipments = self.constraints.apply_shipment_defecture_constraints(\n",
        "                shipments, self.data['defecture']\n",
        "            )\n",
        "        \n",
        "        shipments = self.constraints.apply_box_constraints(shipments)\n",
        "        \n",
        "        return shipments\n",
        "\n",
        "print(\"✓ Класс SalesForecaster определен\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Загрузка данных\n",
        "\n",
        "Теперь все классы определены. Можно загружать данные и запускать прогнозирование.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Загрузка данных\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Путь к данным\n",
        "# Укажите правильный путь к папке с данными\n",
        "data_path = '../data'  # Если notebook в Downloads, а данные в Desktop/project/data\n",
        "# Или:\n",
        "# data_path = 'data'  # Если notebook в папке проекта\n",
        "\n",
        "# Создание загрузчика данных\n",
        "loader = DataLoader(data_path)\n",
        "\n",
        "# Загрузка всех данных\n",
        "data = loader.load_all_data()\n",
        "\n",
        "# Загрузка исторических отгрузок\n",
        "historical_shipments = loader.load_historical_shipments('Отгрузки в МП')\n",
        "\n",
        "print(\"Загруженные данные:\")\n",
        "for key, df in data.items():\n",
        "    if df is not None and not df.empty:\n",
        "        print(f\"  {key}: {len(df)} записей\")\n",
        "    else:\n",
        "        print(f\"  {key}: нет данных\")\n",
        "\n",
        "if historical_shipments is not None and not historical_shipments.empty:\n",
        "    print(f\"\\nИсторические отгрузки: {len(historical_shipments)} записей\")\n",
        "    print(historical_shipments.head())\n",
        "else:\n",
        "    print(\"\\nИсторические отгрузки: файл не найден или пуст\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Эта ячейка удалена - импорты уже есть в ячейке 2\n",
        "# Все классы импортированы из модулей forecasting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Анализ исторических данных отгрузок\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if historical_shipments is not None and not historical_shipments.empty:\n",
        "    print(\"=\"*60)\n",
        "    print(\"АНАЛИЗ ИСТОРИЧЕСКИХ ДАННЫХ ОТГРУЗОК\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Анализ связи между продажами и отгрузками\n",
        "    shipment_calc = ShipmentCalculator()\n",
        "    \n",
        "    # Анализ для Wildberries\n",
        "    if 'wb_sales' in data and not data['wb_sales'].empty:\n",
        "        print(\"\\n📊 Анализ отгрузок для Wildberries:\")\n",
        "        wb_analysis = shipment_calc.analyze_shipment_calculation(\n",
        "            data['wb_sales'],\n",
        "            data.get('wb_stocks', pd.DataFrame()),\n",
        "            historical_shipments\n",
        "        )\n",
        "        if wb_analysis:\n",
        "            print(\"  Результаты анализа:\")\n",
        "            for key, value in wb_analysis.items():\n",
        "                if isinstance(value, (int, float)):\n",
        "                    print(f\"    - {key}: {value:.2f}\")\n",
        "        else:\n",
        "            print(\"  ⚠ Недостаточно данных для анализа\")\n",
        "    \n",
        "    # Анализ для Ozon\n",
        "    if 'ozon_sales' in data and not data['ozon_sales'].empty:\n",
        "        print(\"\\n📊 Анализ отгрузок для Ozon:\")\n",
        "        ozon_analysis = shipment_calc.analyze_shipment_calculation(\n",
        "            data['ozon_sales'],\n",
        "            data.get('ozon_stocks', pd.DataFrame()),\n",
        "            historical_shipments\n",
        "        )\n",
        "        if ozon_analysis:\n",
        "            print(\"  Результаты анализа:\")\n",
        "            for key, value in ozon_analysis.items():\n",
        "                if isinstance(value, (int, float)):\n",
        "                    print(f\"    - {key}: {value:.2f}\")\n",
        "        else:\n",
        "            print(\"  ⚠ Недостаточно данных для анализа\")\n",
        "    \n",
        "    # Визуализация отгрузок\n",
        "    print(\"\\n📈 Построение графиков...\")\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
        "    \n",
        "    # График отгрузок по времени\n",
        "    shipments_by_date = historical_shipments.groupby('date')['quantity'].sum()\n",
        "    axes[0].plot(shipments_by_date.index, shipments_by_date.values, marker='o', linewidth=2)\n",
        "    axes[0].set_title('Исторические отгрузки по времени', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Дата', fontsize=12)\n",
        "    axes[0].set_ylabel('Количество упаковок', fontsize=12)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Топ продуктов по отгрузкам\n",
        "    top_products = historical_shipments.groupby('unified_code')['quantity'].sum().sort_values(ascending=False).head(10)\n",
        "    axes[1].barh(range(len(top_products)), top_products.values, color='steelblue')\n",
        "    axes[1].set_yticks(range(len(top_products)))\n",
        "    axes[1].set_yticklabels(top_products.index)\n",
        "    axes[1].set_title('Топ-10 продуктов по отгрузкам', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('Количество упаковок', fontsize=12)\n",
        "    axes[1].grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"✓ Графики построены\")\n",
        "else:\n",
        "    print(\"⚠ Исторические отгрузки отсутствуют - анализ пропущен\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Настройка параметров прогнозирования\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if historical_shipments is not None and not historical_shipments.empty:\n",
        "    # Анализ связи между продажами и отгрузками\n",
        "    shipment_calc = ShipmentCalculator()\n",
        "    \n",
        "    # Анализ для Wildberries\n",
        "    if 'wb_sales' in data and not data['wb_sales'].empty:\n",
        "        print(\"Анализ отгрузок для Wildberries:\")\n",
        "        wb_analysis = shipment_calc.analyze_shipment_calculation(\n",
        "            data['wb_sales'],\n",
        "            data.get('wb_stocks', pd.DataFrame()),\n",
        "            historical_shipments\n",
        "        )\n",
        "        print(wb_analysis)\n",
        "    \n",
        "    # Анализ для Ozon\n",
        "    if 'ozon_sales' in data and not data['ozon_sales'].empty:\n",
        "        print(\"\\nАнализ отгрузок для Ozon:\")\n",
        "        ozon_analysis = shipment_calc.analyze_shipment_calculation(\n",
        "            data['ozon_sales'],\n",
        "            data.get('ozon_stocks', pd.DataFrame()),\n",
        "            historical_shipments\n",
        "        )\n",
        "        print(ozon_analysis)\n",
        "    \n",
        "    # Визуализация отгрузок\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
        "    \n",
        "    # График отгрузок по времени\n",
        "    shipments_by_date = historical_shipments.groupby('date')['quantity'].sum()\n",
        "    axes[0].plot(shipments_by_date.index, shipments_by_date.values)\n",
        "    axes[0].set_title('Исторические отгрузки по времени')\n",
        "    axes[0].set_xlabel('Дата')\n",
        "    axes[0].set_ylabel('Количество упаковок')\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    # Топ продуктов по отгрузкам\n",
        "    top_products = historical_shipments.groupby('unified_code')['quantity'].sum().sort_values(ascending=False).head(10)\n",
        "    axes[1].barh(range(len(top_products)), top_products.values)\n",
        "    axes[1].set_yticks(range(len(top_products)))\n",
        "    axes[1].set_yticklabels(top_products.index)\n",
        "    axes[1].set_title('Топ-10 продуктов по отгрузкам')\n",
        "    axes[1].set_xlabel('Количество упаковок')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Прогнозирование продаж для Wildberries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создание прогнозировщика\n",
        "forecaster = SalesForecaster(\n",
        "    data_path=data_path,\n",
        "    forecast_months=18\n",
        ")\n",
        "\n",
        "# Загрузка данных в прогнозировщик\n",
        "forecaster.data = data\n",
        "forecaster.data['historical_shipments'] = historical_shipments\n",
        "\n",
        "# Настройка коэффициента покрытия (можно настроить на основе анализа)\n",
        "coverage_coefficient = 1.5  # По умолчанию, можно изменить на основе анализа\n",
        "if historical_shipments is not None and not historical_shipments.empty:\n",
        "    # Если есть анализ, можно использовать его для настройки\n",
        "    # Проверяем, был ли выполнен анализ для WB\n",
        "    if 'wb_sales' in data and not data['wb_sales'].empty:\n",
        "        shipment_calc = ShipmentCalculator()\n",
        "        wb_analysis = shipment_calc.analyze_shipment_calculation(\n",
        "            data['wb_sales'],\n",
        "            data.get('wb_stocks', pd.DataFrame()),\n",
        "            historical_shipments\n",
        "        )\n",
        "        if wb_analysis:\n",
        "            if 'avg_coverage_from_shipments' in wb_analysis:\n",
        "                coverage_coefficient = wb_analysis['avg_coverage_from_shipments']\n",
        "                print(f\"Коэффициент покрытия рассчитан на основе исторических данных: {coverage_coefficient:.2f}\")\n",
        "            elif 'avg_coverage_ratio' in wb_analysis:\n",
        "                coverage_coefficient = wb_analysis['avg_coverage_ratio']\n",
        "                print(f\"Коэффициент покрытия рассчитан на основе остатков: {coverage_coefficient:.2f}\")\n",
        "\n",
        "forecaster.shipment_calculator.set_coverage_coefficient(coverage_coefficient)\n",
        "print(f\"Используемый коэффициент покрытия: {coverage_coefficient}\")\n",
        "\n",
        "# Размеры коробов\n",
        "box_sizes = {\n",
        "    'default': 24  # По умолчанию 24 штуки в коробе\n",
        "}\n",
        "forecaster.constraints.set_box_sizes(box_sizes)\n",
        "print(f\"Размер короба по умолчанию: {box_sizes['default']} шт.\")\n",
        "\n",
        "# Даты черной пятницы\n",
        "ozon_bf = ['2023-11-24', '2024-11-29', '2025-11-28']\n",
        "wb_bf = ['2023-11-24', '2024-11-29', '2025-11-28']\n",
        "forecaster.calendar_features.add_black_friday_dates(ozon_bf, wb_bf)\n",
        "print(f\"Черная пятница настроена\")\n",
        "\n",
        "# Подготовка моделей\n",
        "forecaster.prepare_models()\n",
        "print(f\"\\nПодготовлено {len(forecaster.models)} моделей\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Выбор лучших прогнозов и применение ограничений\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Прогнозирование всеми моделями\n",
        "wb_forecasts = forecaster.forecast_sales(marketplace='wb', evaluate=True)\n",
        "\n",
        "print(f\"Создано прогнозов: {len(wb_forecasts)}\")\n",
        "for model_name, forecast_df in wb_forecasts.items():\n",
        "    print(f\"  {model_name}: {len(forecast_df)} записей\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Расчет отгрузок для Wildberries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Выбор лучших прогнозов для каждого продукта\n",
        "wb_best_forecast = forecaster.select_best_forecasts(wb_forecasts, marketplace='wb')\n",
        "\n",
        "print(f\"Лучший прогноз: {len(wb_best_forecast)} записей\")\n",
        "print(f\"Уникальных продуктов: {wb_best_forecast['unified_code'].nunique()}\")\n",
        "print(f\"\\nРаспределение по моделям:\")\n",
        "print(wb_best_forecast['selected_model'].value_counts())\n",
        "\n",
        "# Применение ограничений\n",
        "wb_best_forecast = forecaster.apply_constraints_to_forecast(wb_best_forecast)\n",
        "\n",
        "print(f\"\\nОбщий прогноз продаж: {wb_best_forecast['quantity'].sum():.0f} шт.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Прогнозирование для Ozon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Расчет отгрузок\n",
        "wb_shipments = forecaster.calculate_shipments(wb_best_forecast, marketplace='wb')\n",
        "\n",
        "print(f\"Отгрузки: {len(wb_shipments)} записей\")\n",
        "if not wb_shipments.empty:\n",
        "    print(f\"Уникальных складов: {wb_shipments['warehouse'].nunique()}\")\n",
        "    print(f\"Уникальных продуктов: {wb_shipments['unified_code'].nunique()}\")\n",
        "    print(f\"Общая отгрузка: {wb_shipments['shipment'].sum():.0f} шт.\")\n",
        "    print(f\"\\nТоп-10 продуктов по отгрузкам:\")\n",
        "    top_shipments = wb_shipments.groupby('unified_code')['shipment'].sum().sort_values(ascending=False).head(10)\n",
        "    print(top_shipments)\n",
        "    \n",
        "    # Визуализация отгрузок\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
        "    \n",
        "    # Отгрузки по времени\n",
        "    shipments_by_date = wb_shipments.groupby('date')['shipment'].sum()\n",
        "    axes[0].plot(shipments_by_date.index, shipments_by_date.values, marker='o')\n",
        "    axes[0].set_title('Прогнозные отгрузки по времени (WB)')\n",
        "    axes[0].set_xlabel('Дата')\n",
        "    axes[0].set_ylabel('Количество упаковок')\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    # Отгрузки по складам\n",
        "    shipments_by_warehouse = wb_shipments.groupby('warehouse')['shipment'].sum().sort_values(ascending=False)\n",
        "    axes[1].barh(range(len(shipments_by_warehouse)), shipments_by_warehouse.values)\n",
        "    axes[1].set_yticks(range(len(shipments_by_warehouse)))\n",
        "    axes[1].set_yticklabels(shipments_by_warehouse.index)\n",
        "    axes[1].set_title('Отгрузки по складам (WB)')\n",
        "    axes[1].set_xlabel('Количество упаковок')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Нет данных об отгрузках\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Оценка моделей\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Прогнозирование для Ozon\n",
        "ozon_forecasts = forecaster.forecast_sales(marketplace='ozon', evaluate=True)\n",
        "ozon_best_forecast = forecaster.select_best_forecasts(ozon_forecasts, marketplace='ozon')\n",
        "ozon_best_forecast = forecaster.apply_constraints_to_forecast(ozon_best_forecast)\n",
        "ozon_shipments = forecaster.calculate_shipments(ozon_best_forecast, marketplace='ozon')\n",
        "\n",
        "print(f\"Ozon - Прогноз продаж: {ozon_best_forecast['quantity'].sum():.0f} шт.\")\n",
        "if not ozon_shipments.empty:\n",
        "    print(f\"Ozon - Отгрузки: {ozon_shipments['shipment'].sum():.0f} шт.\")\n",
        "    print(f\"Ozon - Складов: {ozon_shipments['warehouse'].nunique()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Оценка моделей\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сводка по оценке моделей\n",
        "evaluation_summary = forecaster.evaluator.get_evaluation_summary()\n",
        "best_models_summary = forecaster.evaluator.get_best_models_summary()\n",
        "\n",
        "if not evaluation_summary.empty:\n",
        "    print(\"Оценка моделей:\")\n",
        "    print(evaluation_summary.head(20))\n",
        "    \n",
        "    # Визуализация метрик\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # MAE по моделям\n",
        "    mae_by_model = evaluation_summary.groupby('model_name')['mae'].mean().sort_values()\n",
        "    axes[0, 0].barh(range(len(mae_by_model)), mae_by_model.values)\n",
        "    axes[0, 0].set_yticks(range(len(mae_by_model)))\n",
        "    axes[0, 0].set_yticklabels(mae_by_model.index)\n",
        "    axes[0, 0].set_title('Средний MAE по моделям')\n",
        "    axes[0, 0].set_xlabel('MAE')\n",
        "    \n",
        "    # MAPE по моделям\n",
        "    mape_by_model = evaluation_summary.groupby('model_name')['mape'].mean().sort_values()\n",
        "    axes[0, 1].barh(range(len(mape_by_model)), mape_by_model.values)\n",
        "    axes[0, 1].set_yticks(range(len(mape_by_model)))\n",
        "    axes[0, 1].set_yticklabels(mape_by_model.index)\n",
        "    axes[0, 1].set_title('Средний MAPE по моделям')\n",
        "    axes[0, 1].set_xlabel('MAPE (%)')\n",
        "    \n",
        "    # R² по моделям\n",
        "    r2_by_model = evaluation_summary.groupby('model_name')['r2'].mean().sort_values(ascending=False)\n",
        "    axes[1, 0].barh(range(len(r2_by_model)), r2_by_model.values)\n",
        "    axes[1, 0].set_yticks(range(len(r2_by_model)))\n",
        "    axes[1, 0].set_yticklabels(r2_by_model.index)\n",
        "    axes[1, 0].set_title('Средний R² по моделям')\n",
        "    axes[1, 0].set_xlabel('R²')\n",
        "    \n",
        "    # Распределение лучших моделей\n",
        "    if not best_models_summary.empty:\n",
        "        best_models_dist = best_models_summary['best_model'].value_counts()\n",
        "        axes[1, 1].pie(best_models_dist.values, labels=best_models_dist.index, autopct='%1.1f%%')\n",
        "        axes[1, 1].set_title('Распределение лучших моделей')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if not best_models_summary.empty:\n",
        "    print(\"\\nЛучшие модели по продуктам:\")\n",
        "    print(best_models_summary.head(20))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Сохранение результатов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохранение результатов\n",
        "output_dir = Path('../output')\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Прогнозы продаж\n",
        "wb_best_forecast.to_csv(output_dir / 'wb_forecast.csv', index=False, encoding='utf-8-sig')\n",
        "ozon_best_forecast.to_csv(output_dir / 'ozon_forecast.csv', index=False, encoding='utf-8-sig')\n",
        "print(\"Прогнозы продаж сохранены\")\n",
        "\n",
        "# Отгрузки\n",
        "if not wb_shipments.empty:\n",
        "    wb_shipments.to_csv(output_dir / 'wb_shipments.csv', index=False, encoding='utf-8-sig')\n",
        "    print(\"Отгрузки WB сохранены\")\n",
        "if not ozon_shipments.empty:\n",
        "    ozon_shipments.to_csv(output_dir / 'ozon_shipments.csv', index=False, encoding='utf-8-sig')\n",
        "    print(\"Отгрузки Ozon сохранены\")\n",
        "\n",
        "# Оценка моделей\n",
        "if not evaluation_summary.empty:\n",
        "    evaluation_summary.to_csv(output_dir / 'model_evaluation.csv', index=False, encoding='utf-8-sig')\n",
        "    print(\"Оценка моделей сохранена\")\n",
        "if not best_models_summary.empty:\n",
        "    best_models_summary.to_csv(output_dir / 'best_models.csv', index=False, encoding='utf-8-sig')\n",
        "    print(\"Лучшие модели сохранены\")\n",
        "\n",
        "print(f\"\\nВсе результаты сохранены в папку {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Пример анализа конкретного продукта\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Выберите продукт для анализа\n",
        "if not wb_best_forecast.empty:\n",
        "    product_code = wb_best_forecast['unified_code'].iloc[0]\n",
        "    print(f\"Анализ продукта: {product_code}\")\n",
        "    \n",
        "    # Исторические продажи\n",
        "    if 'wb_sales' in data and not data['wb_sales'].empty:\n",
        "        product_sales = data['wb_sales'][data['wb_sales']['unified_code'] == product_code].copy()\n",
        "        product_sales = product_sales.sort_values('date')\n",
        "        \n",
        "        # Прогноз\n",
        "        product_forecast = wb_best_forecast[wb_best_forecast['unified_code'] == product_code].copy()\n",
        "        product_forecast = product_forecast.sort_values('date')\n",
        "        \n",
        "        # Визуализация\n",
        "        fig, ax = plt.subplots(figsize=(15, 6))\n",
        "        \n",
        "        # Исторические продажи\n",
        "        ax.plot(product_sales['date'], product_sales['quantity'], \n",
        "                label='Исторические продажи', marker='o', alpha=0.7)\n",
        "        \n",
        "        # Прогноз\n",
        "        ax.plot(product_forecast['date'], product_forecast['quantity'], \n",
        "                label='Прогноз', marker='s', linestyle='--', alpha=0.7)\n",
        "        \n",
        "        ax.set_title(f'Продажи и прогноз для продукта {product_code}')\n",
        "        ax.set_xlabel('Дата')\n",
        "        ax.set_ylabel('Количество упаковок')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Выбранная модель\n",
        "        selected_model = product_forecast['selected_model'].iloc[0] if 'selected_model' in product_forecast.columns else 'N/A'\n",
        "        print(f\"Выбранная модель: {selected_model}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
